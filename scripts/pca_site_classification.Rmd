---
title: "pca_site_classification"
author: "Gavin Lemley"
date: "2020-11-17"
output: html_document
---

Load libraries
```{r load libraries}
library(tidyverse)

```

Load data and transform as needed
```{r load data}
root.dir <- rprojroot::find_root("lgss.Rproj")

# Data used in initial run:
# fielddata.path <- file.path(root.dir, "data", "compile_2015-2019", "field_data", "final_cleaned", "2015-2019_lowgrad_fielddata_20201120.csv")

# 5/25/21 - pH values in basin 17 collected on June 2015 trip possibly erroneous. Replaced 14 values with ave of all basin 17 data in AGOL portal (n=160, dates from 1989-2014)
# fielddata.path <- file.path(root.dir, "data", "compile_2015-2019", "field_data", "final_cleaned", "2015-2019_lowgrad_fielddata_20210525.csv")

# 5/26/21 - Erroneous pH value of 2.2 at 17-CARL-0.8 replaced with average of 3 previous visits (2009, 2013, and 2014), value of 6.7. 
fielddata.path <- file.path(root.dir, "data", "compile_2015-2019", "field_data", "final_cleaned", "2015-2019_lowgrad_fielddata_20210526.csv")

landcover.path <- file.path(root.dir, "data", "compile_2015-2019", "landcover", "landcover_final_2015-2019_20201120.csv")
  
# Load data, create unique IDs, and remove duplicate sites.
fielddata <- read.csv(fielddata.path, stringsAsFactors = FALSE) %>% 
  mutate(sample_date = as.Date(sample_date)) %>% 
  # mutate(unique_id = paste0(site_id, "_", format(sample_date, "%Y"))) %>% 
  select(site_id, everything(), -event_id) %>% 
  arrange(site_id, sample_date) %>% 
  distinct(site_id, .keep_all = TRUE)

# Import landcover data generated in landcover.Rmd and clean up site IDs created by ArcGIS to match
landcover <- read.csv(landcover.path, stringsAsFactors = FALSE) %>% 
  mutate(site_id = str_replace(site_id, "_updated", "")) %>% 
  mutate(site_id = str_replace(site_id, "_stretched", "")) %>% 
  mutate(site_id = str_replace(site_id, "_new", "")) %>% 
  mutate(site_id = str_replace(site_id, "d", "_")) %>% 
  rename(site_id_landcover = site_id)

# Join field data with landcover; create alternate modified site id field in field data to join with landcover
fielddata.lc <- fielddata %>% 
  mutate(site_id_landcover = gsub("-", "_", site_id),
         site_id_landcover = gsub("\\.", "_", site_id_landcover)) %>% 
  left_join(landcover, by = "site_id_landcover") %>% 
  select(-site_id_landcover) %>% 
  mutate(landcover_agdev_pct = landcover_dev_pct + landcover_ag_pct) %>% 
  # Filter out sites with lots of missing data
  filter(!(site_id %in% c(
    "03-LSAM_N-7.9",
    "01-BLKE-0.1"))) %>% 
  # Filter out sites to be omitted (low sample counts or poor sample collected)
  filter(!(site_id %in% c(
    "17-PECN-12.4",
    "13-WALK-35.6",
    "13-IDNK-0.5")))   
```

Prepping data for input to PCA
```{r}
# Select only unique id and numeric fields 
fielddata.num <- fielddata.lc %>% 
  select(site_id, which(sapply(.,is.numeric)), -c(basin))

# Count number of non-NA records
datacounts <- data.frame(colname = names(fielddata.num),colSums_fielddata = colSums(!is.na(fielddata.num)))

# List fields in order by lowest value count, then list in console formatted for copy/pasting
# datacounts.vec <- colSums(!is.na(fielddata.num))
# sort(datacounts.vec)
# cat(names(sort(datacounts.vec)), sep = ", ")

## Field selection and cleanup
fielddata.num.sub <- fielddata.num %>% 
  # Remove spotty params and those not present in 2015 data
  select(-c(hab_present, embeddedness, chl_a, biosample, habitat_total_score, clay, rubble, silt, rock, sand, gravel, salinity, algae_diaoms_presen, 
            thickness_diatoms_present, lgs_habitat_snag, lgs_habitat_bank, lgs_habitat_macrophyte, lgs_habitat_substrate, microtox)) %>% 
  # Replace -9999s with NA
  mutate_all(~replace(., . == -9999, NA))
 
# Find means for creating dummy vals
fielddata.num.mean <- fielddata.num.sub %>%
  # summarise(across(everything(), list(min = min, max = max, median = median)))
  # summarise(across(everything(), list(median = median)))
  summarise_each(funs(mean(., na.rm = TRUE)))

datacounts2 <- data.frame(colname = names(fielddata.num.sub),colSums_fielddata=colSums(!is.na(fielddata.num.sub)))

# Fill in dummy values with means and calculate total habitat score
fielddata.dummy <- fielddata.num.sub %>% 
  ### (see Dray and Josse, 2015 for deeper dive into filling in missing vals)
  mutate_at(vars(depth), ~replace_na(., mean(depth, na.rm = TRUE))) %>%
  mutate_at(vars(width), ~replace_na(., mean(width, na.rm = TRUE))) %>%
  mutate_at(vars(cur_spd), ~replace_na(., mean(cur_spd, na.rm = TRUE))) %>%
  mutate_at(vars(canopy), ~replace_na(., mean(canopy, na.rm = TRUE))) %>%
  mutate_at(vars(macrophyte_pct), ~replace_na(., mean(macrophyte_pct, na.rm = TRUE))) %>%
  mutate_at(vars(sediment_deposition), ~replace_na(., mean(sediment_deposition, na.rm = TRUE))) %>%
  mutate_at(vars(embeddedness_pooling), ~replace_na(., mean(embeddedness_pooling, na.rm = TRUE))) %>%
  mutate_at(vars(flow_status), ~replace_na(., mean(flow_status, na.rm = TRUE))) %>%
  mutate_at(vars(channel_alteration), ~replace_na(., mean(channel_alteration, na.rm = TRUE))) %>%
  mutate(habitat_total_score = select(., epifaunal_cover, embeddedness_pooling, velocity_depth_regime, sediment_deposition, flow_status, channel_alteration,
                                      riffle_bend_frequency, left_bank_stability, right_bank_stability, left_bank_veg, right_bank_veg, left_bank_veg_zone, 
                                      right_bank_veg_zone) 
         %>% rowSums(na.rm = TRUE))


# Remove incomplete fields for testing PCA
fielddata.pca.data <- fielddata.dummy  
  # select(-c(depth, width, cur_spd, canopy, macrophyte_pct, sediment_deposition, embeddedness_pooling, flow_status, channel_alteration))

# Subset to only habitat params for plotting on PCA
fielddata.pca.habitatonly <- fielddata.pca.data %>%
  select(site_id, epifaunal_cover, embeddedness_pooling, velocity_depth_regime, sediment_deposition, flow_status, channel_alteration, riffle_bend_frequency, left_bank_stability, right_bank_stability, left_bank_veg, right_bank_veg, left_bank_veg_zone, right_bank_veg_zone)


### Data frames for testing in PCA:

# Remove habitat variables and retain just total habitat score
fielddata.pca.data.clean <- fielddata.pca.data %>%
  select(-c(epifaunal_cover, embeddedness_pooling, velocity_depth_regime, sediment_deposition, flow_status, channel_alteration, riffle_bend_frequency, left_bank_stability, right_bank_stability, left_bank_veg, right_bank_veg, left_bank_veg_zone, right_bank_veg_zone))

# Remove variables that probably don't represent disturbance
fielddata.pca.disturb <- fielddata.pca.data.clean %>% 
  # select(site_id, landcover_nat_pct, landcover_dev_pct, landcover_ag_pct, landcover_water_pct, spcond, ph, habitat_total_score)
  select(-c(depth, width, cur_spd, canopy, do_conc, landcover_water_pct))
fielddata.pca.disturb2 <- fielddata.pca.disturb %>% 
  # select(site_id, landcover_nat_pct, landcover_dev_pct, landcover_ag_pct, landcover_water_pct, spcond, ph, habitat_total_score)
  select(-c(do_pct_sat, temp, landcover_agdev_pct))
fielddata.pca.disturb3 <- fielddata.pca.disturb %>% 
  select(-c(do_pct_sat, temp, landcover_agdev_pct, ph))
fielddata.pca.disturb4 <- fielddata.pca.disturb %>% 
  select(-c(do_pct_sat, temp, landcover_dev_pct, landcover_ag_pct))

# write_csv(fielddata.pca.disturb2, file.path(root.dir, "data", "compile_2015-2019", "condition_classes", "LG_abiotic_pca_variables_20210112.csv"))

# Subset further to remove all landcover but NAT
fielddata.pca.disturb.nat <- fielddata.pca.disturb %>% 
  select(-c(landcover_dev_pct, landcover_ag_pct))

# Same as above using DEV instead of NAT landcover
fielddata.pca.disturb.dev <- fielddata.pca.disturb %>% 
  select(-c(landcover_nat_pct, landcover_ag_pct))

# Subset further to just use NAT, habitat score, and SpCond
fielddata.pca.disturb.simp <- fielddata.pca.disturb.nat %>% 
  select(-c(ph, macrophyte_pct))

```

Load additional libs
```{r}
library(vegan)
library(recipes)
library(rsample)
library(modeldata)
library(ggplot2)
library(ggfortify)
library(corrr)
library(tidymodels)
library(factoextra)
library(here)
```


```{r plotting pca, fig.width=10, fig.height=6}

# fielddata.pca.data
# fielddata.pca.habitatonly
# fielddata.pca.data.clean
# fielddata.pca.disturb
# fielddata.pca.disturb2
# fielddata.pca.disturb.nat
# fielddata.pca.disturb.dev
# fielddata.pca.disturb.simp

### 1st plot:

# Column names to row names 
fielddata.pca.input <- fielddata.pca.disturb2 %>% 
  column_to_rownames(var = "site_id")

# PCA setup and biplot
fielddata.pca.scale <- scale(fielddata.pca.input, center = TRUE, scale = TRUE)
abiotic.pca <- prcomp(fielddata.pca.scale, cor = TRUE)

# Plot PCA Biplot and quantiles of PC1 values
pca_biplot <- autoplot(abiotic.pca, data = fielddata.pca.scale, label = F, label.size = 3, loadings.label = TRUE, loadings.label.repel=T, loadings.label.size = 4, scale= 0)
pca_biplot +
  geom_vline(xintercept = c(-0.87304171, 1.01738099), linetype = "dotdash") +
  annotate("text", x = -3.75, y = -2.75, label = "Most Disturbed", fontface = "bold", size = 4.5) +
  annotate("text", x = 0.1, y = -2.75, label = "Slightly-Moderately\nDisturbed", fontface = "bold", size = 4.5) +
  annotate("text", x =  2.5, y = -2.75, label = "Least Disturbed", fontface = "bold", size = 4.5)
  
  # ggsave(file.path(root.dir, "data/ibi/plots_for_pub", "pca_2021-07-30.png"), dpi = "print")



### 2nd plot:

# # Column names to row names 
# fielddata.pca.input <- fielddata.pca.disturb2 %>% 
#   column_to_rownames(var = "site_id")
# 
# # PCA setup and biplot
# fielddata.pca.scale <- scale(fielddata.pca.input, center = TRUE, scale = TRUE)
# abiotic.pca <- prcomp(fielddata.pca.scale, cor = TRUE)
# 
# # Plot PCA Biplot and quantiles of PC1 values
# pca_biplot <- autoplot(abiotic.pca, data = fielddata.pca.scale, label = FALSE, label.size = 2, loadings.label = TRUE, loadings.label.repel=T, loadings.label.size = 4, scale= 0)
# 
# # vline<- geom_vline(xintercept = c(-1.4769168,-0.4725721,0.9480725))
# # pca_biplot+vline
# pca_biplot

```

Look at correlations between PCs and variables.
```{r,  fig.width=10, fig.height=6}

# Get eigenvalues and join to data
eig.val <- get_eigenvalue(abiotic.pca)

# Get PCA Scores
scores <- abiotic.pca$x
scores <- as.data.frame(scores)
scores <- scores %>% 
  rownames_to_column(var = "site_id")

# Join PCA scores back to original dataset
fielddata.pca.input.forjoin <- fielddata.pca.input %>% 
  rownames_to_column(var = "site_id")

joined <- left_join(fielddata.pca.input.forjoin, scores, by=("site_id"))


# Scree plot - how to quanify results?
fviz_eig(abiotic.pca)

# Examine Kaiser-Guttman criterion & Broken Stick model to determine the number of meaninful principal components to explore (https://en.proft.me/2016/11/15/principal-component-analysis-pca-r/)

ev = abiotic.pca$sdev^2

# BROKEN STICK DOES NOT SUPPORT PC1
# Look at Jackson 1993 paper for additional tests to try.

evplot = function(ev) {
  # Broken stick model (MacArthur 1957)
  n = length(ev)
  bsm = data.frame(j=seq(1:n), p=0)
  bsm$p[1] = 1/n
  for (i in 2:n) bsm$p[i] = bsm$p[i-1] + (1/(n + 1 - i))
  bsm$p = 100*bsm$p/n
  # Plot eigenvalues and % of variation for each axis
  op = par(mfrow=c(2,1),omi=c(0.1,0.3,0.1,0.1), mar=c(2, 2, 2, 2))
  barplot(ev, main="Eigenvalues", col="white", las=1)
  abline(h=mean(ev), col="red")
  return(ev)
  return(mean(ev))
  legend("right", "Average eigenvalue", lwd=1, col=2, bty="n")
  barplot(t(cbind(100*ev/sum(ev), bsm$p[n:1])), beside=TRUE, 
          main="% variation", col=c("lightgray","black"), las=1)
  legend("right", c("% eigenvalue", "Broken stick model"), 
         pch=15, col=c("lightgray","black"), bty="n")
  par(op)
}

evplot(ev)

#Examine correlation between principal components
joined_num<-select_if(joined, is.numeric) %>% 
  select(-c(PC4, PC5, PC6, PC7))
  # select(-c(PC4, PC5))

# Generate and export basic stats of variables
var.stats <- pastecs::stat.desc(joined_num) %>% 
  select(-c(PC1, PC2, PC3))
# write.table(var.stats, file.path(root.dir, "data/pca/pca_variable_stats_2021-07-30.csv"),sep=",", row.names = TRUE)

PC1_corr <- joined_num %>%
  select(-PC2, -PC3) %>%
  correlate(use = "pairwise.complete.obs", method = "spearman") %>%
  focus(PC1)
# write.table(PC1_corr, file.path(root.dir, "data/pca/pc1_corr_2021-07-30.csv"),sep=",", row.names = FALSE)

PC2_corr <- joined_num %>%
  select(-PC1, -PC3) %>%
  correlate(use = "pairwise.complete.obs", method = "spearman") %>%
  focus(PC2)

### Code below no longer works after R 4.0 upgrade

# PC1_corr %>%
#   mutate(rowname = factor(rowname, levels = rowname[order(PC1)])) %>%  # Order by correlation strength
#    ggplot(aes(x = rowname, y = PC1)) +
#   geom_bar(stat = "identity") +
#   ylab("Correlation with PC1") +
#   xlab("Variable")+
#   ylim(-1,1)+
#   theme(axis.text.x=element_text(angle=90,hjust=1))

# PC2_corr %>%
#     mutate(rowname = factor(rowname, levels = rowname[order(PC2)])) %>%  # Order by correlation strength
#     ggplot(aes(x = rowname, y = PC2)) +
#     geom_bar(stat = "identity") +
#     ylab("Correlation with PC2") +
#     xlab("Variable")+
#     ylim(-1,1)+
#     theme(axis.text.x=element_text(angle=90,hjust=1))

```

Classify sites based on PC1 and plot
```{r, fig.width=14, fig.height=8}
class.plot.df <- scores %>% 
  select(site_id, PC1, PC2) %>%  
  # Reclassify sites based on BPJ.
  mutate(basin = substr(site_id, 0, 2),
         PC1 = case_when(
           site_id %in% "11-TOMH-12.2" ~ -5,
           site_id %in% "09-LSUK-11.3" ~ -5,
           # site_id %in% "16-WEBA-23.3" ~ -5,    # Reverted to reference, 6/8/21
           # site_id %in% "13-IDNK-0.5" ~ -5,       # Confirmed tidal; omitted from dataset altogether.
           TRUE ~ PC1
         ))

# Determine Thresholds based on PC1 qauntiles
quantile(class.plot.df$PC1, probs = seq(0, 1, 0.25), na.rm = FALSE, names = TRUE, type = 7)

# Initial run, on fielddata.pca.disturb2:
#         0%        25%        50%        75%       100% 
# -5.4314219 -0.8870725  0.0270505  1.1074533  3.2054342 
    
# Same as initial but w/ bad pH value at 17-CARL-0.8 replaced with ave (6.7 instead of 2.2)
#          0%         25%         50%         75%        100% 
# -5.28126830 -0.88806864 -0.01500482  1.12320423  3.62374899 

# Rerun with PECN-12.4 and WALK-35.6 omitted, and 4 sites forced to class 3.
#           0%          25%          50%          75%         100% 
# -10.00000000  -0.93280967  -0.06879499   0.98344902   3.62597427 

# Rerun with PECN-12.4, WALK-35.6, and INDK-0.5 omitted, and TOMH and LSUK forced to class 3.
         # 0%         25%         50%         75%        100% 
# -5.22359194 -0.87304171 -0.04705769  1.01738099  3.65456958 

all.abiotic.classified<-left_join(fielddata.lc, class.plot.df, by=c("site_id")) %>%
  filter(!(site_id %in% c("03-LSAM_N-7.9", "01-BLKE-0.1"))) %>%
  rename(basin = basin.x) %>%
  select(-basin.y) %>%
  mutate(condition_class = case_when(
    PC1 <= -0.87304171 ~ "3", # Highly Disturbed
    PC1 <= -0.04705769 ~ "2", # Moderately Disturbed (Q3)
    PC1 <= 1.01738099 ~ "2", # Slightly Disturbed (Q2) (grouped with above becuase we're only testing 1 and 3)
    PC1 > 1.01738099 ~ "1", # Least Disturbed
    TRUE                 ~"NOT CLASSIFIED"
  )) %>%
  select(site_id, condition_class, everything(), -PC2)


all.abiotic.classified.long<-all.abiotic.classified %>% 
  select(condition_class, macrophyte_pct, spcond, ph, landcover_nat_pct, landcover_dev_pct, landcover_ag_pct, habitat_total_score) %>% 
  pivot_longer(!condition_class, values_to = "result_value", names_to = "parameter")

p <- all.abiotic.classified.long %>% 
  mutate(condition_class = factor(condition_class, c("1", "2", "3"))) %>%  
  ggplot(aes(condition_class, result_value)) +
  geom_boxplot(outlier.size = 0.5)+
  theme(axis.title.y=element_blank())

p + facet_wrap(vars(parameter), ncol = 3, scales = "free", strip.position = "left", 
                # labeller = as_labeller(c(AGRI = "AGRI (%)", ALK = "ALK (mg/L CaCO3)", CHLA = "CHLA (ug/L)", COND="COND (uS/cm)", DEV="DEV (%)", FOREST = "FOREST (%)", IMPERV= "IMERV (%)", NATURAL = "NATURAL (%)", NH3 = "NH3 (ug/L)", NOx = "NOx (ug/L)", PH = "PH", SECCHI ="SECCHI (m)", TKN = "TKN (ug/L)", TN = "TN (ug/L)", TP = "TP (ug/L)"))
               )
# Plot PCA Scores and categories on biplot w/o loadings

class.plot <- class.plot.df %>% 
  ggplot(aes(x=PC1, y=PC2)) +
  geom_vline(xintercept = c(-0.87304171,-0.04705769,1.01738099), linetype = "dotdash") +
  geom_point(size=3, aes(shape = basin, label = site_id)) +
  scale_shape_manual(values=c(0:40))+
  annotate("text", x = -2, y = -4, label = "Class 3\n(Most Disturbed)")+
  annotate("text", x = 0, y = -4, label = "Class 2\n(Mod. Disturbed)")+
  annotate("text", x =  2, y = -4, label = "Class 1\n(Least Disturbed)")
class.plot

# List unique basins in each category
class.HD.basins <- all.abiotic.classified %>% 
  select(site_id, basin, condition_class) %>% 
  filter(condition_class == "3")
class.MD.basins <- all.abiotic.classified %>% 
  select(site_id, basin, condition_class) %>% 
  filter(condition_class == "2")
class.LD.basins <- all.abiotic.classified %>% 
  select(site_id, basin, condition_class) %>% 
  filter(condition_class == "1")
unique(class.HD.basins$basin)
unique(class.MD.basins$basin)
unique(class.LD.basins$basin)

# # Reclassify sites based on BPJ
# 
# all.abiotic.classified.reclass <- all.abiotic.classified %>%
#   mutate(condition_class = case_when(
#     site_id %in% "11-TOMH-12.2" ~ "3",
#     site_id %in% "09-LSUK-11.3" ~ "3",
#     site_id %in% "16-WEBA-23.3" ~ "3",
#     site_id %in% "13-IDNK-0.5" ~ "3",
#     TRUE ~ condition_class
#   ))
# 
# # Relist unique basins in each category
# class.HD.basins <- all.abiotic.classified.reclass %>% 
#   select(site_id, basin, condition_class) %>% 
#   filter(condition_class == "3")
# class.MD.basins <- all.abiotic.classified.reclass %>% 
#   select(site_id, basin, condition_class) %>% 
#   filter(condition_class == "2")
# class.LD.basins <- all.abiotic.classified.reclass %>% 
#   select(site_id, basin, condition_class) %>% 
#   filter(condition_class == "1")
# unique(class.HD.basins$basin)
# unique(class.MD.basins$basin)
# unique(class.LD.basins$basin)

```

Exporting data
```{r, eval = FALSE}
# Export joined data with classes
write.table(all.abiotic.classified, file.path(root.dir, "data/compile_2015-2019/field_data/2015-2019_LG_field_landcover_condclasses_20210611-reclass.csv"),sep=",", row.names = FALSE)

# Export just the classes for joining elsewhere
classes.export <- all.abiotic.classified %>%
  select(site_id, condition_class, PC1)
write.table(classes.export, file.path(root.dir, "data/compile_2015-2019/condition_classes/2015-2019_LG_condclasses_20210611-reclass.csv"),sep=",", row.names = FALSE)

```

