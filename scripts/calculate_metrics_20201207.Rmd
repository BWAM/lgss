---
title: "calculate_metrics_20201207"
output: html_document
---

# Data prep 

```{r Load main libs and set directories}
library(tidyverse)
library(mmir)

root.dir <- rprojroot::find_root("lgss.Rproj")
datamod.dir <- file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/SMAS - Streams Data Modernization/Cleaned Files/FINAL_RELOADS_SEPT2020")

```


```{r Load sample taxa and prep}

# High counts subsampled down to 200 
taxa.df <- read_csv(file.path(root.dir, "data/compile_2015-2019/bugs", "2015-2019_LGtaxa_unique_long_subsamp_2021-11-30.csv"))

# Not subsampled
# taxa.df <- read_csv(file.path(root.dir, "data/compile_2015-2019/bugs", "2015-2019_lowgrad_taxa_unique_long_speciesfill_2021-11-18.csv"))

# Create nested dataframe
nest.df <- taxa.df %>%
  group_nest(site_id, .key = "data")

```

```{r Misc taxa exploration, eval = FALSE}
taxa.df.coleop.fam <- taxa.df %>% 
  filter(order %in% "coleoptera") #%>% 
  # distinct(family)

taxa.df.distinctsp <- taxa.df %>% 
  distinct(macro_genspecies, .keep_all = "TRUE")

# Seeing if insecta are mostly made up of interolerant/facultative. 
taxa.df.insecta.tol <- taxa.df.distinctsp %>% 
  filter(class %in% "insecta",
         tol_char %in% "tolerant")
taxa.df.insecta.intol <- taxa.df.distinctsp %>% 
  filter(class %in% "insecta",
         tol_char %in% "intolerant")
taxa.df.insecta.fac <- taxa.df.distinctsp %>% 
  filter(class %in% "insecta",
         tol_char %in% "facultative")
taxa.df.insecta.fac.na <- taxa.df.distinctsp %>% 
  filter(is.na(tol_char))
# Turns out they are mostly facultative and intolerant.

# Looking at presence and spread of voltinism data
taxa.df.volt.u <- taxa.df.distinctsp %>% 
  filter(voltinism %in% "univoltine")
taxa.df.volt.s <- taxa.df.distinctsp %>% 
  filter(voltinism %in% "semivoltine")
taxa.df.volt.mult <- taxa.df.distinctsp %>% 
  filter(voltinism %in% "bi_multivoltine")
taxa.df.volt.na <- taxa.df.distinctsp %>% 
  filter(is.na(voltinism))
# ~23% of unique taxa in this dataset do not have voltinism defined!

# Looking at presence and spread of tolerance data
taxa.df.tol.tol <- taxa.df.distinctsp %>% 
  filter(tol_char %in% "tolerant")
taxa.df.tol.int <- taxa.df.distinctsp %>% 
  filter(tol_char %in% "intolerant")
taxa.df.tol.fac <- taxa.df.distinctsp %>% 
  filter(tol_char %in% "facultative")
taxa.df.tol.na <- taxa.df.distinctsp %>% 
  filter(is.na(tol_char))
# ~7% of unique taxa in this dataset do not have voltinism defined.

# Looking at presence and spread of functional feeding group data
taxa.df.ffg.gath <- taxa.df.distinctsp %>% 
  filter(ffg %in% "gatherer")
taxa.df.ffg.shred <- taxa.df.distinctsp %>% 
  filter(ffg %in% "shredder")
taxa.df.ffg.scrp <- taxa.df.distinctsp %>% 
  filter(ffg %in% "scraper")
taxa.df.ffg.pred <- taxa.df.distinctsp %>% 
  filter(ffg %in% "predator")
taxa.df.ffg.filt <- taxa.df.distinctsp %>% 
  filter(ffg %in% "filterer")
taxa.df.ffg.na <- taxa.df.distinctsp %>% 
  filter(is.na(ffg))
# ~9% of unique taxa in this dataset do not have FFG defined.

```


# Calculate metrics

```{r Tolerance Metric (HBI)}

taxa_tol.df <- nest.df %>%
  mutate(
    hbi_taxa_tolerance = taxa_tol_index(.dataframe = .,
                                    .key_col = site_id,
                                    .counts_col = count,
                                    .tol_col = tol_int,
                                    .unnest_col = data)
  ) %>% 
  select(-data)

```

## Richness Metrics

```{r Standard Richness}

rich_std.df <- nest.df %>% 
  mutate(
    # Class level richness
    rich_class = taxa_rich(.dataframe = .,
                           .key_col = site_id,
                           .counts_col = count,
                           .group_col = class,
                           .unnest_col = data),
    # Order level richness
    rich_order = taxa_rich(.dataframe = .,
                           .key_col = site_id,
                           .counts_col = count,
                           .group_col = order,
                           .unnest_col = data),
    # Family level richness
    rich_family = taxa_rich(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = family,
                            .unnest_col = data),
    # Genus level richness
    rich_genus = taxa_rich(.dataframe = .,
                           .key_col = site_id,
                           .counts_col = count,
                           .group_col = genus,
                           .unnest_col = data),
    # Target taxon level richness
    rich_ttaxa = taxa_rich(.dataframe = .,
                           .key_col = site_id,
                           .counts_col = count,
                           .group_col = ttaxa,
                           .unnest_col = data),
    # Non-insecta richness
    rich_non_insecta = taxa_rich(.dataframe = .,
                         .key_col = site_id,
                         .counts_col = count,
                         .group_col = ffg,
                         .unnest_col = data,
                         .filter = !(class %in% "insecta")),
    # # Insecta richness
    # rich_insecta = taxa_rich(.dataframe = .,
    #                      .key_col = site_id,
    #                      .counts_col = count,
    #                      .group_col = ffg,
    #                      .unnest_col = data,
    #                      .filter = class %in% "insecta"),
    # Functional Feeding group richness
    rich_ffg = taxa_rich(.dataframe = .,
                         .key_col = site_id,
                         .counts_col = count,
                         .group_col = ffg,
                         .unnest_col = data,
                         .filter = !is.na(ffg))

    # Tolerance classification richness
    # rich_tolerance = taxa_rich(.dataframe = .,
    #                         .key_col = site_id,
    # .counts_col = count,
    #                         .group_col = tol_char,
    #                         .unnest_col = data,
    #                         .filter = !is.na(tol_char))
    # # Tolerance value richness
    # rich_tolerance_num = taxa_rich(.dataframe = .,
    #                         .key_col = site_id,
    # .counts_col = count,
    #                         .group_col = tol_int,
    #                         .unnest_col = data,
    #                         .filter = !is.na(tol_int))
  ) %>% 
  select(-data)

```

```{r Subgroup Richness}

rich_subgr.df <- nest.df %>%
  mutate(
    rich_ttaxa_ep = taxa_rich(.dataframe = .,
                              .key_col = site_id,
                              .counts_col = count,
                              .group_col = ttaxa,
                              .filter = order %in% c("ephemeroptera",
                                                     "plecoptera"),
                              .unnest_col = data),
    rich_ttaxa_et = taxa_rich(.dataframe = .,
                              .key_col = site_id,
                              .counts_col = count,
                              .group_col = ttaxa,
                              .filter = order %in% c("ephemeroptera",
                                                     "trichoptera"),
                              .unnest_col = data),
    rich_ttaxa_pt = taxa_rich(.dataframe = .,
                              .key_col = site_id,
                              .counts_col = count,
                              .group_col = ttaxa,
                              .filter = order %in% c("plecoptera",
                                                     "trichoptera"),
                              .unnest_col = data),
    rich_ttaxa_ept = taxa_rich(.dataframe = .,
                               .key_col = site_id,
                               .counts_col = count,
                               .group_col = ttaxa,
                               .filter = order %in% c("ephemeroptera",
                                                      "plecoptera",
                                                      "trichoptera"),
                               .unnest_col = data),
    rich_ttaxa_pote = taxa_rich(.dataframe = .,
                                 .key_col = site_id,
                                 .counts_col = count,
                                 .group_col = ttaxa,
                                 .filter = order %in% c("plecoptera",
                                                        "odonata",
                                                        "trichoptera",
                                                        "ephemeroptera"),
                                 .unnest_col = data),
    rich_ttaxa_potec = taxa_rich(.dataframe = .,
                                 .key_col = site_id,
                                 .counts_col = count,
                                 .group_col = ttaxa,
                                 .filter = order %in% c("plecoptera",
                                                        "coleoptera",
                                                        "odonata",
                                                        "trichoptera",
                                                        "ephemeroptera"),
                                 .unnest_col = data),
    # Zach said this is usually specific to lakes, but keep it. May be good for LG.
    rich_ttaxa_cote = taxa_rich(.dataframe = .,
                                .key_col = site_id,
                                .counts_col = count,
                                .group_col = ttaxa,
                                .filter = order %in% c("coleoptera",
                                                       "odonata",
                                                       "trichoptera",
                                                       "ephemeroptera"),
                                .unnest_col = data),
    rich_ttaxa_cot = taxa_rich(.dataframe = .,
                               .key_col = site_id,
                               .counts_col = count,
                               .group_col = ttaxa,
                               .filter = order %in% c("coleoptera",
                                                      "odonata",
                                                      "trichoptera"),
                               .unnest_col = data),
    rich_ttaxa_coe = taxa_rich(.dataframe = .,
                               .key_col = site_id,
                               .counts_col = count,
                               .group_col = ttaxa,
                               .filter = order %in% c("coleoptera",
                                                      "odonata",
                                                      "ephemeroptera"),
                               .unnest_col = data),
    rich_ttaxa_cte = taxa_rich(.dataframe = .,
                               .key_col = site_id,
                               .counts_col = count,
                               .group_col = ttaxa,
                               .filter = order %in% c("coleoptera",
                                                      "trichoptera",
                                                      "ephemeroptera"),
                               .unnest_col = data),
    # Below Metrics were in old LG metrics script
    rich_ttaxa_toe = taxa_rich(.dataframe = .,
                               .key_col = site_id,
                               .counts_col = count,
                               .group_col = ttaxa,
                               .filter = order %in% c("trichoptera",
                                                      "odonata",
                                                      "ephemeroptera"),
                               .unnest_col = data),
    rich_ttaxa_mol = taxa_rich(.dataframe = .,
                               .key_col = site_id,
                               .counts_col = count,
                               .group_col = ttaxa,
                               .filter = phylum %in% "mollusca",
                               .unnest_col = data),
    # Already done in taxa_seq() chunk, but used to calculate subgr
    rich_ttaxa_amphi = taxa_rich(.dataframe = .,
                                 .key_col = site_id,
                                 .counts_col = count,
                                 .group_col = ttaxa,
                                 .filter = order %in% "amphipoda",
                                 .unnest_col = data),
    rich_ttaxa_mol_amph = rich_ttaxa_mol + rich_ttaxa_amphi,
    rich_ttaxa_crust = taxa_rich(.dataframe = .,
                                 .key_col = site_id,
                                 .counts_col = count,
                                 .group_col = ttaxa,
                                 .filter = subphylum %in% "crustacea",
                                 .unnest_col = data),
    rich_ttaxa_mol_crust = rich_ttaxa_crust + rich_ttaxa_mol,
    rich_ttaxa_chironominae = taxa_rich(.dataframe = .,
                                        .key_col = site_id,
                                        .counts_col = count,
                                        .group_col = ttaxa,
                                        .filter = subfamily %in% "chironominae",
                                        .unnest_col = data),
    rich_ttaxa_non_insecta = taxa_rich(.dataframe = .,
                                        .key_col = site_id,
                                        .counts_col = count,
                                        .group_col = ttaxa,
                                        .filter = !(class %in% "insecta"),
                                        .unnest_col = data),
    # Richness of intolerant and facultative Taxa 
    rich_ttaxa_tol_0to7 = taxa_rich(.dataframe = .,
                                    .key_col = site_id,
                                    .counts_col = count,
                                    .group_col = ttaxa,
                                    .filter = tol_int <= 7,
                                    .unnest_col = data)
  ) %>% 
  select(-data)

# rich_subgr.df %>%
#   mutate(data = "nested dataframe") %>%
#   head() %>%
#   knitr::kable()
```


```{r Percent Richness}

rich_pct.df <- nest.df %>% 
  mutate(
    pct_rich_ttaxa_ep = taxa_pct_rich(.dataframe = .,
                                      .key_col = site_id,
                                      .counts_col = count,
                                      .group_col = ttaxa,
                                      .filter = order %in% c("ephemeroptera", 
                                                             "plecoptera"),
                                      .unnest_col = data),
    pct_rich_ttaxa_et = taxa_pct_rich(.dataframe = .,
                                      .key_col = site_id,
                                      .counts_col = count,
                                      .group_col = ttaxa,
                                      .filter = order %in% c("trichoptera",
                                                             "ephemeroptera"),
                                      .unnest_col = data), 
    pct_rich_ttaxa_pt = taxa_pct_rich(.dataframe = .,
                                      .key_col = site_id,
                                      .counts_col = count,
                                      .group_col = ttaxa,
                                      .filter = order %in% c("trichoptera",
                                                             "plecoptera"),
                                      .unnest_col = data), 
    pct_rich_ttaxa_ept = taxa_pct_rich(.dataframe = .,
                                       .key_col = site_id,
                                       .counts_col = count,
                                       .group_col = ttaxa,
                                       .filter = order %in% c("plecoptera",
                                                              "trichoptera",
                                                              "ephemeroptera"),
                                       .unnest_col = data), 
    pct_rich_ttaxa_pote = taxa_pct_rich(.dataframe = .,
                                         .key_col = site_id,
                                         .counts_col = count,
                                         .group_col = ttaxa,
                                         .filter = order %in% c("plecoptera",
                                                                "odonata",
                                                                "trichoptera",
                                                                "ephemeroptera"),
                                         .unnest_col = data), 
    pct_rich_ttaxa_potec = taxa_pct_rich(.dataframe = .,
                                         .key_col = site_id,
                                         .counts_col = count,
                                         .group_col = ttaxa,
                                         .filter = order %in% c("plecoptera",
                                                                "coleoptera",
                                                                "odonata",
                                                                "trichoptera",
                                                                "ephemeroptera"),
                                         .unnest_col = data), 
    pct_rich_ttaxa_cote = taxa_pct_rich(.dataframe = .,
                                        .key_col = site_id,
                                        .counts_col = count,
                                        .group_col = ttaxa,
                                        .filter = order %in% c("coleoptera",
                                                               "odonata",
                                                               "trichoptera",
                                                               "ephemeroptera"),
                                        .unnest_col = data),
    pct_rich_ttaxa_cot = taxa_pct_rich(.dataframe = .,
                                       .key_col = site_id,
                                       .counts_col = count,
                                       .group_col = ttaxa,
                                       .filter = order %in% c("coleoptera",
                                                              "odonata",
                                                              "trichoptera"),
                                       .unnest_col = data),
    pct_rich_ttaxa_toe = taxa_pct_rich(.dataframe = .,
                                       .key_col = site_id,
                                       .counts_col = count,
                                       .group_col = ttaxa,
                                       .filter = order %in% c("odonata",
                                                              "trichoptera",
                                                              "ephemeroptera"),
                                       .unnest_col = data),
    pct_rich_ttaxa_cte = taxa_pct_rich(.dataframe = .,
                                       .key_col = site_id,
                                       .counts_col = count,
                                       .group_col = ttaxa,
                                       .filter = order %in% c("coleoptera",
                                                              "trichoptera",
                                                              "ephemeroptera"),
                                       .unnest_col = data),
    pct_rich_ttaxa_coe = taxa_pct_rich(.dataframe = .,
                                       .key_col = site_id,
                                       .counts_col = count,
                                       .group_col = ttaxa,
                                       .filter = order %in% c("coleoptera",
                                                              "odonata",
                                                              "ephemeroptera"),
                                       .unnest_col = data),
    pct_rich_ttaxa_mol = taxa_pct_rich(.dataframe = .,
                                       .key_col = site_id,
                                       .counts_col = count,
                                       .group_col = ttaxa,
                                       .filter = phylum %in% "mollusca",
                                       .unnest_col = data), 
    pct_rich_ttaxa_crust = taxa_pct_rich(.dataframe = .,
                                         .key_col = site_id,
                                         .counts_col = count,
                                         .group_col = ttaxa,
                                         .filter = subphylum %in% "crustacea",
                                         .unnest_col = data), 
    pct_rich_ttaxa_chironominae = taxa_pct_rich(.dataframe = .,
                                                .key_col = site_id,
                                                .counts_col = count,
                                                .group_col = ttaxa,
                                                .filter = subfamily %in% "chironominae",
                                                .unnest_col = data),
    pct_rich_ttaxa_non_insecta = taxa_pct_rich(.dataframe = .,
                                                .key_col = site_id,
                                                .counts_col = count,
                                                .group_col = ttaxa,
                                                .filter = !(class %in% "insecta"),
                                                .unnest_col = data),
     # pct_rich_ttaxa_insecta = taxa_pct_rich(.dataframe = .,
     #                                            .key_col = site_id,
     #                                            .counts_col = count,
     #                                            .group_col = ttaxa,
     #                                            .filter = class %in% "insecta",
     #                                            .unnest_col = data),
   # Percent Richness of Intolerant and Facultative Taxa
    pct_rich_ttaxa_tol_0to7 = taxa_pct_rich(.dataframe = .,
                                            .key_col = site_id,
                                            .counts_col = count,
                                            .group_col = ttaxa,
                                            .filter = tol_int <= 6,
                                            .unnest_col = data)
  ) %>% 
  select(-data)

```


## Diversity Metrics

```{r Diversity}

div.df <- nest.df %>%
  mutate(
    shannon_ttaxa = taxa_div(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .group_col = ttaxa,
                             .job = "shannon",
                             .base_log = 2,
                             .q = NA,
                             .unnest_col = data),
    simpson_ttaxa = taxa_div(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .group_col = ttaxa,
                             .job = "simpson",
                             .q = NA,
                             .unnest_col = data),
    margalef_ttaxa = taxa_div(.dataframe = .,
                              .key_col = site_id,
                              .counts_col = count,
                              .group_col = ttaxa,
                              .job = "margalef",
                              .q = NA,
                              .unnest_col = data),
    menhinick_ttaxa = taxa_div(.dataframe = .,
                               .key_col = site_id,
                               .counts_col = count,
                               .group_col = ttaxa,
                               .job = "menhinick",
                               .q = NA,
                               .unnest_col = data),
    pielou_ttaxa = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .job = "pielou",
                            .q = NA,
                            .unnest_col = data)
  ) %>% 
  select(-data)

# div.df %>%
#   mutate(data = "nested dataframe") %>%
#   head() %>%
#   knitr::kable()
```

```{r Subgroup Diversity}

div_subgr.df <- nest.df %>%
  mutate(
    gini_simpson_ttaxa_ept = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .filter = order %in% c("ephemeroptera",
                                                   "plecoptera",
                                                   "trichoptera"),
                            .job = "gini_simpson",
                            .q = NA,
                            .unnest_col = data),
    gini_simpson_ttaxa_toe = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .filter = order %in% c("ephemeroptera",
                                                   "odonata",
                                                   "trichoptera"),
                            .job = "gini_simpson",
                            .q = NA,
                            .unnest_col = data),
    gini_simpson_ttaxa_et = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .filter = order %in% c("ephemeroptera",
                                                   "trichoptera"),
                            .job = "gini_simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_ept = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .filter = order %in% c("ephemeroptera",
                                                   "plecoptera",
                                                   "trichoptera"),
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_et = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .filter = order %in% c("ephemeroptera",
                                                   "trichoptera"),
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_pote = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("plecoptera",
                                                   "odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_potec = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "plecoptera",
                                                   "odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_cote = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_cot = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "odonata",
                                                   "trichoptera"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_toe = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_coe = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "odonata",
                                                   "ephemeroptera"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_cte = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    simpson_ttaxa_non_insecta = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = !(class %in% "insecta"), 
                            .job = "simpson",
                            .q = NA,
                            .unnest_col = data),
    shannon_ttaxa_ept = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .filter = order %in% c("ephemeroptera",
                                                   "plecoptera",
                                                   "trichoptera"),
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),
    shannon_ttaxa_et = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .filter = order %in% c("ephemeroptera",
                                                   "trichoptera"),
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),
    shannon_ttaxa_pote = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("plecoptera",
                                                   "odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),  
    shannon_ttaxa_potec = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "plecoptera",
                                                   "odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),  
    shannon_ttaxa_cote = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),  
    shannon_ttaxa_cot = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "odonata",
                                                   "trichoptera"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),    
    shannon_ttaxa_toe = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("odonata",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),  
    shannon_ttaxa_cte = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "trichoptera",
                                                   "ephemeroptera"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),  
    shannon_ttaxa_coe = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = order %in% c("coleoptera",
                                                   "odonata",
                                                   "ephemeroptera"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),
    shannon_ttaxa_non_insecta = taxa_div(.dataframe = .,
                            .key_col = site_id,
                            .group_col = ttaxa,
                            .counts_col = count,
                            .filter = !(class %in% "insecta"), 
                            .job = "shannon",
                            .base_log = 2,
                            .q = NA,
                            .unnest_col = data),
    # margalef_ttaxa_toe = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "margalef",
    #                         .filter = order %in% c("odonata",
    #                                                "trichoptera",
    #                                                "ephemeroptera"), 
    #                         .unnest_col = data),
    # menhinick_ttaxa_toe = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "menhinick",
    #                         .filter = order %in% c("odonata",
    #                                                "trichoptera",
    #                                                "ephemeroptera"), 
    #                         .unnest_col = data),
    # pielou_ttaxa_toe = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "pielou",
    #                         .filter = order %in% c("odonata",
    #                                                "trichoptera",
    #                                                "ephemeroptera"), 
    #                         .unnest_col = data),
    # margalef_ttaxa_et = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "margalef",
    #                         .filter = order %in% c("trichoptera",
    #                                                "ephemeroptera"), 
    #                         .unnest_col = data),
    # menhinick_ttaxa_et = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "menhinick",
    #                         .filter = order %in% c("trichoptera",
    #                                                "ephemeroptera"), 
    #                         .unnest_col = data),
    # pielou_ttaxa_et = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "pielou",
    #                         .filter = order %in% c("trichoptera",
    #                                                "ephemeroptera"), 
    #                         .unnest_col = data),
    # Diversity of Intolerant and Facultative Taxa
    # shannon_ttaxa_tol_0to7 = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .group_col = ttaxa,
    #                         .counts_col = count,
    #                         .filter = tol_int <=7,
    #                         .job = "shannon",
    #                         .base_log = 2,
    #                         .unnest_col = data),
    # simpson_ttaxa_tol_0to7 = taxa_div(.data = .,
    #                         .key_col = site_id,
    #                         .group_col = ttaxa,
    #                         .counts_col = count,
    #                         .filter = tol_int <=7,
    #                         .job = "simpson",
    #                         .unnest_col = data)
    # margalef_ttaxa_tol_0to7 = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "margalef",
    #                         .filter = tol_int <=7,
    #                         .unnest_col = data),
    # menhinick_ttaxa_tol_0to7 = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "menhinick",
    #                         .filter = tol_int <=7,
    #                         .unnest_col = data),
    # pielou_ttaxa_tol_0to7 = taxa_div(.dataframe = .,
    #                         .key_col = site_id,
    #                         .counts_col = count,
    #                         .group_col = ttaxa,
    #                         .job = "pielou",
    #                         .filter = tol_int <=7,
    #                         .unnest_col = data)
  ) %>% 
  select(-data)

# div_subgr.df %>%
#   mutate(data = "nested dataframe") %>%
#   head() %>%
#   knitr::kable()
```

## Dominance Metrics

```{r Dominance}

dom.df <- nest.df %>%
  mutate(
    dom_1_ttaxa = taxa_dom(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .dom_level = 1,
                            .unnest_col = data),
    dom_2_ttaxa = taxa_dom(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .dom_level = 2,
                            .unnest_col = data),
    dom_3_ttaxa = taxa_dom(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .dom_level = 3,
                            .unnest_col = data),
    dom_4_ttaxa = taxa_dom(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .dom_level = 4,
                            .unnest_col = data),
    dom_5_ttaxa = taxa_dom(.dataframe = .,
                            .key_col = site_id,
                            .counts_col = count,
                            .group_col = ttaxa,
                            .dom_level = 5,
                            .unnest_col = data)
  ) %>% 
  select(-data)

# dom.df %>%
#   mutate(data = "nested dataframe") %>%
#   head() %>%
#   knitr::kable()
```


## Community Metrics

```{r Percentages}

pct.df <- nest.df %>% 
  mutate(
     pct_ep = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("ephemeroptera", 
                                                    "plecoptera"),
                             .unnest_col = data),
     pct_et = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("trichoptera",
                                                    "ephemeroptera"),
                             .unnest_col = data), 
     pct_pt = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("trichoptera",
                                                    "plecoptera"),
                             .unnest_col = data), 
     pct_ept = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("plecoptera",
                                                    "trichoptera",
                                                    "ephemeroptera"),
                             .unnest_col = data), 
     pct_pote = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("plecoptera",
                                                    "odonata",
                                                    "trichoptera",
                                                    "ephemeroptera"),
                             .unnest_col = data), 
     pct_potec = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("plecoptera",
                                                    "coleoptera",
                                                    "odonata",
                                                    "trichoptera",
                                                    "ephemeroptera"),
                             .unnest_col = data), 
     pct_cote = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("coleoptera",
                                                    "odonata",
                                                    "trichoptera",
                                                    "ephemeroptera"),
                             .unnest_col = data),
     pct_toe = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("odonata",
                                                    "trichoptera",
                                                    "ephemeroptera"),
                             .unnest_col = data), 
     pct_cot = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("coleoptera",
                                                    "odonata",
                                                    "trichoptera"),
                             .unnest_col = data),
     pct_cte = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("coleoptera",
                                                    "trichoptera",
                                                    "ephemeroptera"),
                             .unnest_col = data),
     pct_coe = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = order %in% c("coleoptera",
                                                    "odonata",
                                                    "ephemeroptera"),
                             .unnest_col = data),
     pct_mol = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = phylum %in% "mollusca",
                             .unnest_col = data), 
     pct_crust = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = subphylum %in% "crustacea",
                             .unnest_col = data), 
     pct_chironominae = taxa_pct(.dataframe = .,
                             .key_col = site_id,
                             .counts_col = count,
                             .filter = subfamily %in% "chironominae",
                             .unnest_col = data),
     pct_non_insecta = taxa_pct(.dataframe = .,
                                .key_col = site_id,
                                .counts_col = count,
                                .filter = !(class %in% "insecta"),
                                .unnest_col = data)
) %>% 
  select(-data)
# pct.df %>%
#   mutate(data = "nested dataframe") %>%
#   head() %>%
#   knitr::kable()

```


## Sequence Metrics

```{r}

seq.df <- nest.df %>%
  # Append all of the results as columns to a single DF.
  bind_cols(
    # Sequence through ttaxa for each unique column specified in the .filter_cols_vec.
    taxa_seq(.dataframe = .,
             .key_col = site_id,
             .counts_col = count,
             .filter_cols_vec = c("class",
                                  "order",
                                  "family",
                                  "tol_char",
                                  "ffg",
                                  "habit",
                                  "voltinism"),
             .group_col = ttaxa,
             .job = "rich",
             .exclude_pattern = "undetermined",
             .unnest_col = data),
    # Sequence through each unique column specified in the .filter_cols_vec 
    # to calculate ttaxa percent richness.
    taxa_seq(.dataframe = .,
             .key_col = site_id,
             .counts_col = count,
             .filter_cols_vec = c("class",
                                  "order",
                                  "family",
                                  "tol_char",
                                  "ffg",
                                  "habit",
                                  "voltinism"),
             .group_col = ttaxa,
             .job = "pct_rich",
             .exclude_pattern = "undetermined",
             .unnest_col = data),
    taxa_seq(.dataframe = .,
             .key_col = site_id,
             .counts_col = count,
             .filter_cols_vec = c("class",
                                  "order",
                                  "suborder",
                                  "family",
                                  "genus",
                                  "tol_char",
                                  "ffg",
                                  "habit",
                                  "voltinism"),
             .job = "pct",
             .exclude_pattern = "undetermined",
             .unnest_col = data),
    # Spot-checked that manual pct_amphi came out the same as pct_NULL_amphipoda (produced by below)
    taxa_seq(.dataframe = .,
             .key_col = site_id,
             .counts_col = count,
             .filter_cols_vec = c("class",
                                  "order", 
                                  "family",
                                  "tol_char",
                                  "ffg",
                                  "habit",
                                  "voltinism"),
             .group_col = ttaxa,
             .base_log = 2,
             .job = "shannon",
             .exclude_pattern = "undetermined",
             .unnest_col = data),
    taxa_seq(.dataframe = .,
             .key_col = site_id,
             .counts_col = count,
             .filter_cols_vec = c("class",
                                  "order", 
                                  "family",
                                  "tol_char",
                                  "ffg",
                                  "habit",
                                  "voltinism"),
             .group_col = ttaxa,
             .job = "simpson",
             .exclude_pattern = "undetermined",
             .unnest_col = data)
  ) %>% 
  select(-data)

seq.names <- as.data.frame(names(seq.df))

```



## Combine metrics dataframes

```{r}
# metrics.all <- div_subgr.df %>%
#   left_join(div.df) %>% 
#   left_join(dom.df) %>% 
#   left_join(rich_std.df) %>% 
#   left_join(rich_pct.df) %>% 
#   left_join(pct.df) %>% 
#   left_join(rich_subgr.df) %>% 
#   left_join(taxa_tol.df) %>% 
#   left_join(seq.df)

# Cleaner way to join
metrics.df <- list(  div_subgr.df,
                     div.df,
                     dom.df,
                     rich_std.df,
                     rich_pct.df,
                     pct.df,
                     rich_subgr.df,
                     taxa_tol.df,
                     seq.df
                   ) %>% 
  plyr::join_all(., by = c("site_id"))

metrics.names <- names(metrics.df)
metrics.names.df <- as.data.frame(metrics.names, col.names = c("metrics", "x")) %>% 
  filter(!metrics.names %in% "site_id",
         !metrics.names %in% "condition_class")

# Invesitage rich_ffg issues
# metrics.df.rich_ffg <- metrics.df %>% 
#   select(site_id, condition_class, rich_ffg)
# Checks out OK


# Look for dups
# metrics.dups <- metrics.names.df %>%
#   mutate(n = n()) %>%
#   group_by(metrics.names) %>%
#   filter(n>1)
# 
#   group_by(accession) %>%
#   mutate(n = n()) %>%
#   filter(n > 1)
# 
# metrics.dups %>% janitor::get_dupes(metrics.all)
# 
# # library(digest)
# test <- metrics.all[!duplicated(lapply(metrics.all, digest::digest))]


# Attach disturbance categories
# condition <- read.csv(file.path("C:/Data/LGSS_scripting/lgss/data/compile_2015-2019/condition_classes", "2015-2019_LG_condclasses_20201216.csv")) %>%   select(-PC1)

# 5/26/21 - New condition classes created due to erroneous pH value found. Had to regenerate PCA (11 sites changed classes)
# condition <- read.csv(file.path("C:/Data/LGSS_scripting/lgss/data/compile_2015-2019/condition_classes", "2015-2019_LG_condclasses_20210526_CARL-pHfixed.csv")) %>%   select(-PC1)

# 6/8/21 - New condition classes after omitting and reclassifying sites (see PCA script)
condition <- read.csv(file.path("C:/Data/LGSS_scripting/lgss/data/compile_2015-2019/condition_classes", "2015-2019_LG_condclasses_20210611-reclass.csv")) %>%   
  select(-PC1)

metrics.df <- metrics.df %>%
  left_join(., condition) %>% 
  select(site_id, condition_class, everything()) #%>% 
  # filter(!is.na(condition_class))

# Investigate certain metrics and bugs
# metrics.sub <- metrics.all %>% 
#   select(site_id, pct_amphi, pct_NULL_amphipoda)

# Join site class to taxa
taxa.df.class <- taxa.df %>% left_join(condition, by = "site_id")

# Look at plecop only
taxa.df.class.plecop <- taxa.df.class %>% filter(order %in% "plecoptera")

```

```{r Clean up workspace}
rm(taxa.df,
   nest.df,
   div_subgr.df,
   div.df,
   dom.df,
   rich_std.df,
   rich_pct.df,
   pct.df,
   rich_subgr.df,
   taxa_tol.df,
   seq.df,
   seq.names)
```


## PMA calculation

Percent Model Affinity of Orders - (PMA-O) Is a measure of order level similarity to a model based
on the reference streams Novak and Bode (1992).
```{r, eval = FALSE}

#### SKIP THIS CHUNK AND RUN TO PMA CALCULATION CHUNK THEN COME BACK TO THIS CHUNK AND RERUN FROM HERE DOWN ###

######
## WARNING: The constants below are from the training set produced used set.seed(80) prior to the Rstudio update that changed the outcome. They were changed before I realized that this issue had occurred. If rerunning using this original training set, use those constants entered in the Rmd prior to 1/5/21 (access previous github commit).
######
metrics.df <- metrics.df %>% 
    mutate(PMA_clitellata = train.df.PMA$pct_clitellata,
           PMA_ephemeroptera = train.df.PMA$pct_ephemeroptera,
           PMA_plecoptera = train.df.PMA$pct_plecoptera,
           PMA_coleoptera = train.df.PMA$pct_coleoptera,
           PMA_trichoptera = train.df.PMA$pct_trichoptera,
           PMA_chironomidae = train.df.PMA$pct_chironomidae,
           PMA_other = train.df.PMA$other
    ) %>%
  group_by(site_id) %>% 
  mutate(pct_other = sum(pct_clitellata, pct_ephemeroptera, pct_plecoptera, pct_coleoptera, pct_trichoptera, pct_chironomidae)) %>% 
  mutate(pct_other = 100 - pct_other) %>% 
  ungroup() %>% 
  mutate(PMA_value_clitellata = case_when(
    PMA_clitellata < pct_clitellata ~ PMA_clitellata,
    PMA_clitellata > pct_clitellata ~ pct_clitellata,
  )) %>% 
  mutate(PMA_value_ephemeroptera = case_when(
    PMA_ephemeroptera < pct_ephemeroptera ~ PMA_ephemeroptera,
    PMA_ephemeroptera > pct_ephemeroptera ~ pct_ephemeroptera,
  )) %>% 
  mutate(PMA_value_plecoptera = case_when(
    PMA_plecoptera < pct_plecoptera ~ PMA_plecoptera,
    PMA_plecoptera > pct_plecoptera ~ pct_plecoptera,
  )) %>% 
  mutate(PMA_value_coleoptera = case_when(
    PMA_coleoptera < pct_coleoptera ~ PMA_coleoptera,
    PMA_coleoptera > pct_coleoptera ~ pct_coleoptera,
  )) %>%   
  mutate(PMA_value_trichoptera = case_when(
    PMA_trichoptera < pct_trichoptera ~ PMA_trichoptera,
    PMA_trichoptera > pct_trichoptera ~ pct_trichoptera,
  )) %>% 
  mutate(PMA_value_chironomidae = case_when(
    PMA_chironomidae < pct_chironomidae ~ PMA_chironomidae,
    PMA_chironomidae > pct_chironomidae ~ pct_chironomidae,
  )) %>% 
  mutate(PMA_value_other = case_when(
    PMA_other < pct_other ~ PMA_other,
    PMA_other > pct_other ~ pct_other,
  )) %>% 
  group_by(site_id) %>% 
  mutate(PMA = sum(PMA_value_clitellata, PMA_value_ephemeroptera, PMA_value_plecoptera, PMA_value_coleoptera, PMA_value_trichoptera, PMA_value_chironomidae, PMA_value_other)) %>% 
  ungroup() %>% 
  select(-c(PMA_value_clitellata, PMA_value_ephemeroptera, PMA_value_plecoptera, PMA_value_coleoptera, PMA_value_trichoptera, PMA_value_chironomidae, PMA_value_other))


# Should come out as the following for current setup (as of 7/16/21)
# # A tibble: 1 x 8
#   site_id pct_clitellata pct_ephemeroptera pct_plecoptera pct_coleoptera pct_trichoptera pct_chironomidae other
#     <dbl>          <dbl>             <dbl>          <dbl>          <dbl>           <dbl>            <dbl> <dbl>
# 1      NA           5.34              10.2          0.222           6.42            3.96             35.3  38.5

```

# Subsampling
```{r Split into training and test (validation) datasets}

library(tidymodels)

# Keep the set.seed number the same to get the same subsampled traning dataset for each run. (Change this to create a new training dataset. Original is 80)

### Run multiple subsamples then set final seed for training.
set.seed(60)
# set.seed(70)
# set.seed(80)
# set.seed(90)
# set.seed(5122)

train_test_split <- metrics.df %>% 
  # mutate(condition_class = factor(condition_class, levels = c("1","3","4","2"))) %>% 
  # filter(condition_class %in% c("1", "3")) %>%
  rsample::initial_split(prop = 2/3, strata = condition_class)

# Create training dataset
train.df <- training(train_test_split) %>% 
  filter(condition_class %in% c("1", "3"),
         !site_id %in% "07-JACB-1.9")

# Create testing dataset
test.df <- testing(train_test_split) %>% 
  filter(condition_class %in% c("1", "3"))

# List sites for each
test.df.vec <- c(test.df$site_id)
train.df.vec <- c(train.df$site_id)

  
#######################
#######################

### Export final training/test site lists for import later on if not reproducible with set.seed().

# write.csv(test.df.vec, file.path(root.dir, "data/metrics/june2021_rerun/test_subsample_setseed90_2021-06-01.csv"), row.names = F)
# write.csv(train.df.vec, file.path(root.dir, "data/metrics/june2021_rerun/train_subsample_setseed90_2021-06-01.csv"), row.names = F)
# 
# write.csv(test.df, file.path(root.dir, "data/metrics/june2021_rerun/test_subsample_setseed60_allmetrics_2021-06-14.csv"), row.names = F)
# write.csv(train.df, file.path(root.dir, "data/metrics/june2021_rerun/train_subsample_setseed60_allmetrics_2021-06-14.csv"), row.names = F)

##################


```

# Calculating pct comp for PMA metric above
```{r}
### Determining percent composition of each major group for PMA calculation above

train.df.PMA <- train.df %>% 
  filter(condition_class == "1") %>% 
  group_by(site_id) %>% 
  select(site_id, 
         pct_clitellata,   #Represents Oligochaeta
         pct_ephemeroptera, 
         pct_plecoptera, 
         pct_coleoptera, 
         pct_trichoptera,
         pct_chironomidae)  %>% 
  mutate(other = sum(pct_clitellata, pct_ephemeroptera, pct_plecoptera, pct_coleoptera, pct_trichoptera, pct_chironomidae)) %>% 
  mutate(other= 100-other) %>% 
  ungroup() %>% 
  summarise_all(list(mean))


### Could also calculate PMA for FFG Composition (PMA-FFG)


# Should have the following output for current run:

# > train.df.PMA
# # A tibble: 1 x 8
#   site_id pct_clitellata pct_ephemeroptera pct_plecoptera pct_coleoptera pct_trichoptera pct_chironomidae other
#     <dbl>          <dbl>             <dbl>          <dbl>          <dbl>           <dbl>            <dbl> <dbl>
# 1      NA           5.42              10.2          0.231           6.52            3.90             35.1  38.5

```

# Calculating sensitivies and initial filtering 
```{r Calculate Sensitivity and filter}

# For full dataset
# long.all.df <- metrics.df %>% 
#   pivot_longer(cols = c(-condition_class, -site_id),
#                names_to = "metric",
#                values_to = "value")
# 
# sens.all.df <- mmir::sensitivity(.dataframe = long.all.df,
#                               .metric_col = metric,
#                               .value_col = value,
#                               .condition_col = condition_class,
#                               .reference = "1",
#                               .degraded = "3") 

# For training dataset
long.df <- train.df %>% 
  pivot_longer(cols = c(-condition_class, -site_id),
               names_to = "metric",
               values_to = "value")

sens.df <- mmir::sensitivity(.dataframe = long.df,
                              .metric_col = metric,
                              .value_col = value,
                              .condition_col = condition_class,
                              .reference = "1",
                              .degraded = "3") 

DT::datatable(sens.df, options = list(scrollX = TRUE))

sensitive_mets.vec <- sens.df %>% 
  filter(barbour >= 2) %>% 
  # Shull et al., ,2019 uses >70%
  filter(de >= 65) %>%
  pull(metric)

# Creating training dataset
train_sensitive.df <- train.df %>% 
  select(condition_class, all_of(sensitive_mets.vec)) %>% 
  mutate(condition_class = as.character(condition_class))

# Creating cross-validation set. Comes into play later during validation...
train_10cv.df <- train_sensitive.df %>% 
  rsample::vfold_cv(v = 10, repeats = 1, strata = condition_class)


# Creating testing dataset
test_sensitive.df <- test.df %>% 
  select(condition_class, all_of(sensitive_mets.vec)) %>% 
  mutate(condition_class = as.character(condition_class))

test_10cv.df <- test_sensitive.df %>% 
  rsample::vfold_cv(v = 10, repeats = 1, strata = condition_class)

# Look at FFG metrics: "predator"  "gatherer"  "shredder"  "filterer"  "scraper"   "collector"
sens.df.ffg <- sens.df %>% 
  filter(grepl("predator|gatherer|shredder|filterer|scraper|collector", metric))

# write.csv(sens.df, file.path(root.dir, "data/metrics/nov2021_rerun_subsampling/metrics_sens_seed60_20211221_JACB_omitted.csv"))
# write.csv(sens.df.ffg, file.path(root.dir, "data/metrics/june2021_rerun/metrics_sens_seed70-FFG_20210603.csv"))

```


```{r Range filtering}

sens.df.subset <- train.df %>% 
  select(site_id, condition_class, all_of(sensitive_mets.vec))

# Find mins and maxes
sens.df.subset.range <- sens.df.subset %>%
  select(-condition_class) %>% 
  summarise_at(vars(-site_id), range) %>%
  rownames_to_column() %>%
  rename(summary_stat = rowname) %>% 
   mutate(summary_stat = case_when(
     summary_stat == 1 ~ "min",
     summary_stat == 2 ~ "max"))

# Transform, calculate ranges, and categorize
range <- sens.df.subset.range %>%
  gather(metric, value, -summary_stat) %>% 
  spread(summary_stat, value) %>% 
  mutate(range = max - min) %>%
  mutate(metric_type = case_when(
    grepl("pct", metric) ~ "pct",
    grepl("dom", metric) ~ "pct",
    grepl("rich", metric) ~ "rich",
    grepl("shannon", metric) ~ "div",
    grepl("margalef", metric) ~ "div",
    grepl("simpson", metric) ~ "div",
    grepl("pielou", metric) ~ "div",
    grepl("menhinick", metric) ~ "div",
    TRUE ~ "MISSING"
  )) 

# Drop pct metrics >10, richness >5, div >1 (as per Matt. Refs?)
rangefail.pct <- range %>% 
  filter(metric_type == "pct",
         range <  10)
rangefail.rich <- range %>% 
  filter(metric_type == "rich",
         range <  5)
rangefail.div <- range %>% 
  filter(metric_type == "div",
         range < 1)

metrics.drop.range <- bind_rows(rangefail.pct, rangefail.rich, rangefail.div) %>% 
  pull(metric) %>% 
  unique()

rm(rangefail.pct, rangefail.rich, rangefail.div)

# sens.df.subset.mean<-sens.df.subset %>%
#   select(-condition_class) %>% 
#   summarise_at(vars(-site_id), mean) %>%
#   rownames_to_column() %>%
#   rename(summary_stat=rowname) %>% 
#    mutate(summary_stat = case_when(
#      summary_stat== 1 ~ "mean"))
# 
# 
# sens.df.subset.IQR<-sens.df.subset %>%
#    filter(condition_class=="1") %>% 
#   select(-condition_class) %>% 
#   summarise_at(vars(-site_id), IQR) %>%
#   rownames_to_column() %>%
#   rename(summary_stat=rowname) %>% 
#    mutate(summary_stat = case_when(
#      summary_stat== 1 ~ "IQR"))
```



```{r Similarity across sites}
#Determine which metrics have >50% same values across all sites. Picks out metrics that have poor ability to differentiate btw sites.
  # Different from filtering by range b/c could have high range but many similar output values (poor differentiation). 
# Matt reference?

sens.df.subset.long <- sens.df.subset %>% 
  select(-condition_class) %>% 
  pivot_longer(!site_id, names_to = "metric", values_to = "value")

sens.df.rank <- sens.df %>% 
  unite("rank",metric, barbour, de, disturbance, sep = "_", remove = FALSE) %>% 
  select(rank, metric)

sens.df.subset.long <- left_join(sens.df.subset.long, sens.df.rank, by = c("metric"))

# sens.df.subset.wide<-sens.df.subset.long %>% 
#   select(-metric) %>% 
#   rename(metric=rank) %>% 
#   pivot_wider(names_from = metric, values_from = value)

sens.df.subset.long.round <- sens.df.subset.long %>% 
  mutate(value = case_when(
    str_detect(metric, "rich_") ~ round(value, digits = 0),
    str_detect(metric, "pct_") ~ ceiling(value),
    str_detect(metric, "shannon_") ~ round(value, digits = 1),
    str_detect(metric, "simpson_") ~ round(value, digits = 1),
    str_detect(metric, "margalef_") ~ round(value, digits = 1),
    str_detect(metric, "menhinick_") ~ round(value, digits = 1),
    str_detect(metric, "pielou_") ~ round(value, digits = 1),
    str_detect(metric, "dom_") ~  ceiling(value),
    TRUE ~ value
    
  ))

sens.df.subset.long.count <- sens.df.subset.long %>%
  group_by(metric, value) %>% 
  count(value) %>%
  ungroup() %>% 
  mutate(n_samples = 40) %>% 
  mutate(percent_similar = ((n/n_samples)*100)) %>% 
  group_by(metric, percent_similar) %>% 
  filter(percent_similar >= 50)

metrics.drop.sim <- sens.df.subset.long.count %>% 
  pull(metric)

# redund.metrics <-  sens.df.subset.long.count %>% 
#   pull(metric) %>% 
#   unique()
# cat(redund.metrics, sep = ", ")
```


Relative scope of impairment (SOI) looks at variability of metrics for ref sites. If varies by more than IQR, then potentially not a good metric bc too much variability among reference sites compared to the range of impairment.

Calculated as the ratio of the IQR of reference sites and the range of possible impairment (values beyond the poorer quality 25th percentile). Relative SOI values greater than 1 indicate too much variability among reference sites compared to the range of impairment. (See Blocksom 2002, 2009 (uses reverse equation))
```{r SOI}

# Take metrics that pass 1st screening, Filter to ref, combine metric name and predicted response (increase/decrease), take lower 25% for decrease, take top 75% for increase, take IQR

reference_sites <- sens.df.subset %>% 
  filter(condition_class == "1") %>% 
  select(site_id)
reference.vec <- c(reference_sites$site_id)

SOI.df <- sens.df.subset.long %>%
  filter(site_id %in% c(reference.vec)) %>% 
  group_by(metric) %>% 
  mutate(Q1 = case_when(
    str_detect(rank, "_decrease") ~ quantile(value, probs = 0.25),
    str_detect(rank, "_increase") ~ quantile(value, probs = 1),
    TRUE ~ value
  )) %>% 
  mutate(Q2 = case_when(
    str_detect(rank, "_decrease") ~ quantile(value, probs = 0),
    str_detect(rank, "_increase") ~ quantile(value, probs = 0.75),
    TRUE ~ value
  )) %>% 
  mutate(IQR = IQR(value)) %>% 
  ungroup() %>% 
  distinct(metric, Q1, Q2, IQR)

SOI.df <- SOI.df %>% 
  mutate(SOI = (IQR/(Q1 - Q2)))

metrics.drop.SOI <- SOI.df %>% 
  filter(SOI > 1) %>% 
  pull(metric)

# Investigating previously dropped metrics:
# metrics.drop.SOI_2 <- SOI.df %>% 
#   filter(SOI >= 1,
#          SOI <= 2) %>% 
#   pull(metric)
# 
# setdiff(metrics.drop.SOI_2, metrics.drop.SOI)
# setdiff(metrics.drop.SOI, metrics.drop.SOI_2)

```


# Metrics reduction stage 2

```{r Compile and remove underperforming metrics}

# Compile list of metrics to drop
metrics.drop <- c(metrics.drop.range, metrics.drop.SOI, metrics.drop.sim) %>% 
  unique()

train.df.sens <- train.df %>% 
  select(site_id, condition_class, all_of(sensitive_mets.vec), -all_of(metrics.drop)) 
    
```


```{r Redundancy by correlation, fig.width=8, fig.height=8}
library(corrr)

# Plot correlations of remaining metrics
# Bowman (yr?; GLIMPSS): "While there is no consensus on “hard cutoffs” for detecting metric redundancy, several workers have chosen r-values in excess of 0.75 (Maxted et al. 2000, Blocksom and Johnson 2009), 0.85 (Butcher et al. 2003, Gerritsen et al. 2000a), and 0.90 (Barbour et al. 1996) to screen for metric redundancy. For GLIMPSS development, we chose Pearson r-values of 0.75 as the cutoff"


corr.sens <- train.df.sens %>% 
  select(-condition_class, -site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman") %>% 
  rearrange() %>% 
  shave()
corr.sens_rownames <- corr.sens %>%
  # mutate_all(~replace(., is.na(.), 1)) %>% 
  remove_rownames %>% 
  column_to_rownames(var = "term")  
corr.sens_highcorr <- corr.sens_rownames %>%
  abs() %>% 
  round(digits = 3) %>% 
  rownames_to_column() %>%
  # Remove values < 0.9
  mutate_all(funs(replace(., . <= 0.75, NA))) %>%
  # Remove columns and rows with all NAs
  column_to_rownames() %>% 
  purrr::discard(~all(is.na(.))) %>% 
  filter_all(any_vars(!is.na(.)))
ggcorrplot::ggcorrplot(corr.sens_rownames)

# Same as above for only cond class 1  (as per Shull et al. 2019)
corr.sens.cc1 <- train.df.sens %>% 
  filter(condition_class %in% "1") %>% 
  select(-condition_class, -site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman") %>% 
  rearrange() %>% 
  shave()
corr.sens_rownames.cc1 <- corr.sens.cc1 %>%
  # mutate_all(~replace(., is.na(.), 1)) %>% 
  remove_rownames %>% 
  column_to_rownames(var = "term")  
corr.sens_highcorr.cc1 <- corr.sens_rownames.cc1 %>%
  abs() %>% 
  round(digits = 3) %>% 
  rownames_to_column() %>%
  # Remove values < 0.9
  mutate_all(funs(replace(., . <= 0.75, NA))) %>%
  # Remove columns and rows with all NAs
  column_to_rownames() %>% 
  purrr::discard(~all(is.na(.))) %>% 
  filter_all(any_vars(!is.na(.)))
ggcorrplot::ggcorrplot(corr.sens_rownames.cc1)



## LOOK AT SCATTERPLOTS OF THOSE W/ CORR'S ABOVE THRESHOLD to see if there are relationships other than linear (indicates duplicate metrics).
# Use psych package (see abiotic corr plots Rmd).

  # Shull et al. 2019: "Metrics with correlation coefficients > 0.75 were evaluated further by visually inspecting scatterplots. Candidate metrics with correlation coefficients > 0.75 and insufficient spread in the scatterplot were removed as candidate metrics."
 # Bowman: "...metric pairs approaching or slightly exceeding this value were further examined using scatterplots to see if nonlinear relationships were apparent or if there was sufficient dispersion (i.e., scatter) of the paired metric data points (Barbour et al. 1999). In this case, inclusion of both metrics could be beneficial to the multi-metric index."



```

```{r Table: highly correlated metrics}
DT::datatable(head(corr.sens_highcorr.cc1, 500), options = list(scrollX = TRUE))

```


```{r Filtered metric boxplots, fig.width=12, fig.height=18}

# train.df.sens.long <- train.df.sens %>% 
#   pivot_longer(!c(site_id, condition_class), names_to = "metric", values_to="value")
# 
# train.df.sens.long2 <- tidyr::gather(train.df.sens, metric, value, -site_id, -condition_class)  #%>% 
  # left_join(condition.df, by = "bas_loc_rm")


# Get list of filtered metrics to this point
metrics.filt <- train.df.sens %>% 
  select(-c(site_id, condition_class)) %>% 
  names() %>% 
  sort()

# metrics.filt_OLD <- train.df.sens_OLD %>% 
#   select(-c(site_id, condition_class)) %>% 
#   names() %>% 
#   sort()

# setdiff(metrics.filt, metrics.filt_OLD)


sens.df %>% 
  filter(metric %in% metrics.filt) %>%
  # filter(barbour == 3) %>% 
  arrange(metric) %>% 
  inner_join(long.df, by = "metric") %>% 
  mutate(metric = factor(metric, levels = unique(metric)),
         condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
  ggplot(aes(condition_class, value)) +
  geom_boxplot() +
  facet_wrap(~metric, ncol = 4, scales = "free")

# sens.df %>% 
#   filter(metric %in% "rich_ffg") %>%
#   # filter(barbour == 3) %>% 
#   arrange(metric) %>% 
#   inner_join(long.df, by = "metric") %>% 
#   mutate(metric = factor(metric, levels = unique(metric)),
#          condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
#   ggplot(aes(condition_class, value)) +
#   geom_boxplot() +
#   facet_wrap(~metric, ncol = 4, scales = "free")

```

```{r View sens table for filtered metrics, eval=TRUE}
sens.filt <- sens.df %>% 
  filter(metric %in% metrics.filt)

DT::datatable(head(sens.filt, 500), options = list(scrollX = TRUE))

# write.csv(sens.filt, file.path(root.dir, "data/metrics/june2021_rerun/sens.filt_seed5122_2021-11-28.csv"))
```


# Final metrics boxplots

```{r Final metrics boxplots}

# Final set #1
# metrics.final <- c("dom_5_ttaxa", "pct_rich_ttaxa_cote", "rich_ttaxa_et", "rich_ttaxa_gatherer", "rich_ttaxa_intolerant", "shannon_ttaxa_toe")

# Final set #2 - Same as above removing pct_rich_ttaxa_cote, which is highly correlated with rich_taxa_et and shannon_taxa_toe.
# metrics.final <- c("dom_5_ttaxa", "rich_ttaxa_et", "rich_ttaxa_gatherer", "rich_ttaxa_intolerant", "shannon_ttaxa_toe")
    # results in 101 '0' metric scores. No metrics intercorr above 0.75.

# Final set #3 - Similar to above using more inclusive counterparts to see if results in <101 '0' metric scores.
# metrics.final <- c("dom_5_ttaxa", "rich_ttaxa_ept", "rich_ttaxa_gatherer", "rich_ttaxa_tol_0to7", "shannon_ttaxa_toe")
    # results in only 64 '0' metric scores. Better final IBI DE! Able to score more sites.
    # shannon_ttaxa_toe corr w rich_ttaxa_tol_0to7 at 0.77. But arguement to keep both, since different groups (one diversity, other tolerance/richness?)
    ### FINAL CHOSEN SET ###

# Final set #4 - Adding back in pct_rich_ttaxa_cote.
# metrics.final <- c("dom_5_ttaxa", "pct_rich_ttaxa_cote", "rich_ttaxa_ept", "rich_ttaxa_gatherer", "rich_ttaxa_tol_0to7", "shannon_ttaxa_toe")
    # No significant difference. (68 '0' metrics scores)

# Final set #5 - Subbing in even more inclusing metric with slighly lower DE's.
# metrics.final <- c("dom_5_ttaxa", "rich_ttaxa", "rich_ttaxa_gatherer", "rich_ttaxa_tol_0to7", "shannon_ttaxa_cote")
    # results in only 20 '0' metric scores!  BUT overall poorer DE.

# Final set #6 - Resample using "new" set.seed(80) subsample. New metrics chosen based on new training sensitivities.
# metrics.final <- c("dom_5_ttaxa", "pct_gatherer", "rich_ttaxa", "rich_ttaxa_toe", "rich_ttaxa_tol_0to7", "shannon_ttaxa_toe", "pct_rich_ttaxa_cte")

# Final set #7 
# metrics.final <- c("dom_5_ttaxa", "pct_gatherer", "rich_ttaxa", "pct_rich_ttaxa_toe", "rich_ttaxa_tol_0to7", "shannon_ttaxa_toe")

# Final set #8 - rich_ttaxa_tol_0to7 removed (high corr w 3 others)
# metrics.final <- c("dom_5_ttaxa", "pct_gatherer", "rich_ttaxa", "pct_rich_ttaxa_toe", "shannon_ttaxa_toe")

# Final set #9 - rich_ttaxa_tol_0to7 removed (high corr w 3 others)
# metrics.final <- c("dom_5_ttaxa", "shannon_ttaxa_shredder", "rich_ttaxa_tol_0to7", "rich_ttaxa_toe", "rich_ttaxa", "shannon_ttaxa_toe")
# metrics.final <- c("dom_5_ttaxa", "rich_ttaxa_tol_0to7", "rich_ttaxa_toe", "rich_ttaxa", "shannon_ttaxa_toe")
# metrics.final <- c("dom_5_ttaxa", "rich_ttaxa_tol_0to7", "rich_ttaxa", "shannon_ttaxa_toe")

# Final set #10 - 2 sites omitted and 4 reclasses
# set.seed 70
# metrics.final <- c("rich_ttaxa_insecta", "dom_3_ttaxa", "shannon_ttaxa_shredder", "shannon_ttaxa_cote")

# Final set #12 - 3 sites omitted, and 2 reclasses
# set.seed 70
# metrics.final <- c("rich_ttaxa_tol_0to7", "pct_rich_ttaxa_coe", "rich_ttaxa_toe", "shannon_ttaxa_shredder", "dom_4_ttaxa", "shannon_ttaxa_toe")
# metrics.final <- c("rich_ttaxa_tol_0to7",	"pct_rich_ttaxa_coe",	"rich_ttaxa_pote",	"shannon_ttaxa_shredder",	"dom_4_ttaxa",	"shannon_ttaxa_cte",	"shannon_ttaxa_pote")
# metrics.final <- c("rich_ttaxa_tol_0to7",	"pct_rich_ttaxa_coe",	"shannon_ttaxa_shredder",	"dom_4_ttaxa",	"shannon_ttaxa_pote")
# metrics.final <- c("rich_ttaxa_tol_0to7",	"rich_ttaxa_pote",	"shannon_ttaxa_shredder",	"dom_4_ttaxa",	"shannon_ttaxa_pote")

# set 13 - set.seed(80), 6/14/21
# metrics.final <- c("rich_ttaxa_tol_0to7", "pct_rich_ttaxa_insecta", "rich_ttaxa_cote", "pct_gatherer", "dom_4_ttaxa", "shannon_ttaxa_pote")
# metrics.final <- c("pct_rich_ttaxa_insecta", "pct_gatherer", "dom_4_ttaxa", "shannon_ttaxa_pote")

# set 14 - seed 5122, 6/14/21
# metrics.final <- c("rich_ttaxa_tol_0to7", "rich_ttaxa_insecta", "pct_rich_ttaxa_non_insecta", "menhinick_ttaxa", "shannon_ttaxa_coe", "pct_gatherer")
# metrics.final <- c("rich_ttaxa_tol_0to7", "rich_ttaxa_insecta", "menhinick_ttaxa", "shannon_ttaxa_coe", "pct_gatherer")

# set 15 - seed 60, 6/14/21
# metrics.final <- c("rich_ttaxa_tol_0to7", "rich_ttaxa_insecta", "pct_rich_ttaxa_non_insecta", "menhinick_ttaxa", "shannon_ttaxa_coe", "pct_gatherer")
# metrics.final <- c("rich_ttaxa_tol_0to7", "rich_ttaxa_coe", "rich_ttaxa_insecta", "shannon_ttaxa_shredder", "shannon_ttaxa_cte", "shannon_ttaxa_toe")
# metrics.final <- c("rich_ttaxa_tol_0to7", "rich_ttaxa_coe", "rich_ttaxa_insecta", "shannon_ttaxa_shredder", "shannon_ttaxa_cte")
# metrics.final <- c("rich_ttaxa_coe", "rich_ttaxa_insecta", "shannon_ttaxa_shredder", "shannon_ttaxa_cte", "shannon_ttaxa_toe",	"shannon_ttaxa_pote",	"shannon_ttaxa_et",	"shannon_ttaxa_ept", "shannon_ttaxa_coe", "shannon_ttaxa_cote", "shannon_ttaxa_potec")
# metrics.final <- c("rich_ttaxa_coe", "rich_ttaxa_insecta", "shannon_ttaxa_shredder", "shannon_ttaxa_cte")

# Post-subsampling updates, 11/28/21
# metrics.final <- c("rich_ttaxa_coe", "rich_ttaxa_insecta", "pct_gatherer", "shannon_ttaxa_coe", "rich_genus", "shannon_ttaxa_shredder")
metrics.final <- c("rich_ttaxa_coe", "rich_ttaxa_insecta", "pct_gatherer", "rich_genus", "shannon_ttaxa_shredder")


#plot final chosen metrics
# sens.df %>% 
#   filter(metric %in% metrics.final) %>%
#   arrange(metric) %>% 
#   inner_join(long.df, by = "metric") %>% 
#   mutate(metric = factor(metric, levels = unique(metric)),
#          condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
#   ggplot(aes(condition_class, value)) +
#   geom_boxplot() +
#   facet_wrap(~metric, ncol = 4, scales = "free")

#plot final chosen metrics (same plot as above, didn't need sens.df)
long.df %>% 
  filter(metric %in% metrics.final) %>%
  arrange(metric) %>% 
  mutate(metric = factor(metric, levels = unique(metric)),
         condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
  ggplot(aes(condition_class, value)) +
  geom_boxplot() +
  facet_wrap(~metric, ncol = 4, scales = "free")

# plot specific metrics
sens.df %>% 
  filter(metric %in% c("simpson_ttaxa_univoltine", "pct_rich_ttaxa_gammaridae",	"shannon_ttaxa_univoltine")) %>%
  arrange(metric) %>% 
  inner_join(long.df, by = "metric") %>% 
  mutate(metric = factor(metric, levels = unique(metric)),
         condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
  ggplot(aes(condition_class, value)) +
  geom_boxplot() +
  facet_wrap(~metric, ncol = 5, scales = "free")

# sens.df %>% 
#   filter(metric %in% c("pct_plecoptera", "rich_ttaxa_plecoptera", "pct_rich_ttaxa_plecoptera", "shannon_ttaxa_plecoptera", "simpson_ttaxa_plecoptera")) %>%
#   # filter(barbour == 3) %>% 
#   arrange(metric) %>% 
#   inner_join(long.df, by = "metric") %>% 
#   mutate(metric = factor(metric, levels = unique(metric)),
#          condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
#   ggplot(aes(condition_class, value)) +
#   geom_boxplot() +
#   facet_wrap(~metric, ncol = 4, scales = "free")

sens.final <- sens.df %>% 
  filter(metric %in% metrics.final)

# Export boxplots and sensitivites of the final metrics for the current run
# ggsave(file.path(root.dir, "data/ibi/reruns", "metrics_boxplots_seed60_20210616.png"), dpi = "screen")
# write_csv(sens.final, file.path(root.dir, "data/ibi/reruns/sens_final_seed80new_20210106.csv"))


```

```{r Corr plot for final metrics}

train.df.final <- train.df.sens %>% 
  select(site_id, condition_class, all_of(metrics.final))

### CREATE PLOTS USING PSYCH PACKAGE ###

corr.final.cc1 <- train.df.final %>% 
  filter(condition_class %in% "1") %>% 
  select(-condition_class, -site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman") %>% 
  rearrange() %>% 
  shave()
corr.final_rownames.cc1 <- corr.final.cc1 %>%
  # mutate_all(~replace(., is.na(.), 1)) %>% 
  remove_rownames %>% 
  column_to_rownames(var = "term")  
tryCatch({
  corr.final_highcorr.cc1 <- corr.final_rownames.cc1 %>%
    abs() %>% 
    round(digits = 3) %>% 
    rownames_to_column() %>%
    # Remove values < 0.9
    # mutate_all(funs(replace(., . <= 0.8, NA))) %>%
    # Remove columns and rows with all NAs
    column_to_rownames() %>% 
    purrr::discard(~all(is.na(.))) %>% 
    filter_all(any_vars(!is.na(.)))},
  error = function(e){cat("ERROR :",conditionMessage(e), "\n")}
)

ggcorrplot::ggcorrplot(corr.final_rownames.cc1)
```
# Metric corr w abiotic variables

```{r Metric corr w abiotic variables}


#### MUST UPDATE ABIOTIC TABLE BELOW WITH NEW VERSION BEFORE USING THIS FOR FIGS ####


# Import sample dates for rejoining
sample.dates <- read_csv(file.path(root.dir, "data", "compile_2015-2019", "bugs", "2015-2019_lowgrad_bugs_UNIQUEdates_20210111.csv"))

# Import abiotic data (from PCA site classification script) and join sample dates
abiotic <- read_csv(file.path(root.dir, "data", "compile_2015-2019", "condition_classes", "LG_abiotic_pca_variables_20210112.csv")) %>% 
  left_join(sample.dates, by = "site_id") 
  # select(-sample_date, -uniqueid)

rm(sample.dates)

# Import chem data for 2017-2019 samples (does not exist for 2015 & 2016) and transform as needed
abiotic.chem <- read_csv(file.path(root.dir, "data/chemistry/2017-2019_chem_lowgrad_assoc_20210111.csv")) %>% 
  mutate(result_value = ifelse(lab_qualifiers %in% "U", method_detection_limit/2, result_value),
         chemical_name = paste0(chemical_name, "_", result_unit)) %>% 
  filter(!is.na(result_value)) %>% 
  mutate(year = substr(sample_date, 3, 4),
    uniqueid = paste0(site_id, "_", year)) %>%
  select(-year) %>% 
  select(site_id, uniqueid, sample_date, chemical_name, result_value) %>% 
  group_by(site_id, chemical_name) %>% 
  spread(chemical_name, result_value) %>% 
# Only retain unique sites used in IBI dev (some were resampled in 2017-2019)
  filter(uniqueid %in% abiotic$uniqueid) %>% 
  select(-c(sample_date, uniqueid, "temperature of ph analysis_deg c", "conductivity at 25 degrees celsius_umhos/cm", "ph_pH units", "chlorophyll a_ug/l", "silver_ug/l"
            #  "nitrogen, kjeldahl, total", "nitrogen"
            )) %>% 
  filter(!(site_id %in% c(
    "17-PECN-12.4",
    "13-WALK-35.6",
    "13-IDNK-0.5")))

abiotic <- abiotic %>% 
  select(-sample_date, -uniqueid)


# train.df.sens.2 <- train.df.final %>% 
#   select(-condition_class)

# test.class2.df.cor <- test.class2.df %>% 
#   select(site_id, all_of(metrics.final))

# Abiotic param correlations w metrics (training)
# metrics.cor.abiotic<-left_join(train.df.final.2, abiotic, by=c("site_id"))
# metric.param.corr<-metrics.cor.abiotic %>% 
#   select(-site_id) %>% 
#   correlate(use = "pairwise.complete.obs", method = "spearman")
# metric.param.corr<-metric.param.corr %>% 
#   select(term, dom_5_ttaxa, pct_gatherer, rich_ttaxa, rich_ttaxa_toe, rich_ttaxa_tol_0to7, shannon_ttaxa_toe, pct_rich_ttaxa_cte) %>%
#   slice(8:14) %>% 
#   remove_rownames %>% 
#   column_to_rownames(var="term")  
# ggcorrplot::ggcorrplot(metric.param.corr)

# Abiotic param correlations w metrics (validation)
test.df.cor <- test.df %>% 
  select(site_id, all_of(metrics.final))

metrics.cor.abiotic<-left_join(test.df.cor, abiotic, by=c("site_id"))
metric.param.corr<-metrics.cor.abiotic %>% 
  select(-site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman")
metric.param.corr<-metric.param.corr %>% 
  select(term, all_of(metrics.final)) %>%
  slice(6:99) %>%
  remove_rownames %>% 
  column_to_rownames(var="term")  
ggcorrplot::ggcorrplot(metric.param.corr)

## Plot above w validation + class 2?

# Chemistry (independent dataset) correlations w metrics (all sites (44), final metrics)
chemsites.metrics.final <- metrics.df %>%
  select(site_id, all_of(metrics.final)) %>% 
  filter(site_id %in% abiotic.chem$site_id)

metrics.cor.chem<-left_join(chemsites.metrics.final, abiotic.chem, by=c("site_id"))
metric.param.corr.chem<-metrics.cor.chem %>% 
  select(-site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman")
metric.param.corr.chem<-metric.param.corr.chem %>% 
  select(term, all_of(metrics.final)) %>% 
  slice(6:99) %>%
  remove_rownames %>% 
  column_to_rownames(var="term")  
ggcorrplot::ggcorrplot(metric.param.corr.chem)

# Chemistry (independent dataset) correlations w metrics (training only; 12 site matches)
train.df.final.2 <- train.df.final %>%
  select(-condition_class)

metrics.cor.chem<-left_join(train.df.final.2, abiotic.chem, by=c("site_id"))
metric.param.corr.chem<-metrics.cor.chem %>% 
  select(-site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman")
metric.param.corr.chem<-metric.param.corr.chem %>% 
  select(term, all_of(metrics.final)) %>%
  slice(6:99) %>%
  remove_rownames %>% 
  column_to_rownames(var="term")  
ggcorrplot::ggcorrplot(metric.param.corr.chem)

# Chemisty param correlations w metrics (validation only; 9 SITES ONLY)
metrics.cor.chem<-left_join(test.df.cor, abiotic.chem, by=c("site_id"))
metric.param.corr.chem<-metrics.cor.chem %>%
  select(-site_id) %>%
  correlate(use = "pairwise.complete.obs", method = "spearman")
metric.param.corr.chem<-metric.param.corr.chem %>%
  select(term, all_of(metrics.final)) %>%
  slice(6:99) %>%
  remove_rownames %>%
  column_to_rownames(var="term")
ggcorrplot::ggcorrplot(metric.param.corr.chem)


# Chemistry (independent dataset) correlations w metrics (all sites, filtered metrics)
chemsites.metrics.filt <- metrics.df %>%
  select(site_id, all_of(metrics.filt)) %>% 
  filter(site_id %in% abiotic.chem$site_id)

metrics.cor.chem<-left_join(chemsites.metrics.filt, abiotic.chem, by=c("site_id"))
metric.param.corr.chem<-metrics.cor.chem %>% 
  select(-site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman")
metric.param.corr.chem<-metric.param.corr.chem %>% 
  select(term, all_of(metrics.filt)) %>% 
  slice(28:99) %>%
  remove_rownames %>% 
  column_to_rownames(var="term")  
ggcorrplot::ggcorrplot(metric.param.corr.chem)

# ggsave(file.path(root.dir, "data/metrics/abiotic_corr", "metrics_chem_corr_seed80new_filt_20210212.png"), dpi = "print")


# Look at cumulative correlations for each metric
metric.abiotic.corscore <- metric.param.corr %>% 
  abs()
colSums(metric.abiotic.corscore) %>% 
   knitr::kable()

# metric.chem.corscore <- metric.param.corr.chem %>% 
#   abs() %>% 
#   mutate(sum = rowSums(.))

metric.chem.corscore2 <- metric.param.corr.chem %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "metric") %>%
  mutate(corrscore = abs(rowSums(.[2:13]))) %>% 
  select(metric, corrscore, everything())

metric.chem.corscore3 <- metric.chem.corscore2 %>% 
  filter(metric %in% metrics.final)

# colSums(metric.chem.corscore) %>% 
#    knitr::kable()

# write_csv(metric.chem.corscore2, file.path(root.dir, "data/metrics/abiotic_corr", "metrics_chem_corr_scores_20210113.csv"))


```


# Traditional IBI method


```{r Prep and plot prior to standardization}

metrics.df.final <- metrics.df %>%
   select(site_id, condition_class, all_of(metrics.final)) 

metrics.df.standardized.long <- metrics.df.final %>% 
  select(-condition_class) %>%
  pivot_longer(!site_id, names_to = "metric", values_to = "value") %>% 
  left_join(sens.df, by = "metric") %>% 
  left_join(condition) 

#plot individual metrics before rescaling
metrics.df.standardized.long %>% 
  filter(metric %in% metrics.final,
         (!(condition_class %in% 2))) %>%
  arrange(metric) %>% 
  arrange(condition_class) %>% 
  mutate(metric = factor(metric, levels = unique(metric)),
         condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
  ggplot(aes(condition_class, value)) +
  geom_boxplot() +
  facet_wrap(~metric, ncol = 4, scales = "free") +
  ggtitle("Final metrics (train+val)")

#plot individual metrics before rescaling - TRAINING ONLY
metrics.df.standardized.long %>%
  filter(site_id %in% train.df.vec) %>%
  filter(metric %in% metrics.final) %>%
  arrange(metric) %>%
  arrange(condition_class) %>%
  mutate(metric = factor(metric, levels = unique(metric)),
         condition_class = factor(condition_class, levels = unique(condition_class))) %>%
  ggplot(aes(condition_class, value)) +
  geom_boxplot() +
  facet_wrap(~metric, ncol = 4, scales = "free") +
  ggtitle("Final metrics (training)")

```


```{r Standardize - Method 1 (simple quantiles), eval=FALSE}
# Using simple quantiles for floors/ceilings

# Determine floor and ceiling thresholds using training only
# THIS BLOCK USES the 95th/5th for ceiling/floor of all training data
# metrics.thresholds <- metrics.df.standardized.long %>%
#   filter(site_id %in% train.df.vec) %>%
#   group_by(metric) %>%
#   mutate(floor = quantile(value, probs = 0.05)) %>%
#   mutate(ceiling =  quantile(value, probs = 0.95)) %>%
#   ungroup() %>%
#   select(metric, disturbance, floor, ceiling) %>%
#   distinct()

# Determine floor and ceiling thresholds using training only, using class 1 and class 3, respectively
# THIS BLOCK USES the 75th of class 1 for ceiling and 25th of class 3 for floor (for metrics that decrease with disturbance), or the inverse for metrics that increase with disturbance 

metrics.thresholds <- metrics.df.standardized.long %>%
  filter(site_id %in% train.df.vec,
         condition_class != 2) %>%
  group_by(metric, condition_class) %>%
  mutate(floor = quantile(value, probs = 0.25)) %>%
  mutate(ceiling =  quantile(value, probs = 0.75)) %>%
  ungroup() %>%
  select(metric, disturbance, floor, ceiling, condition_class) %>%
  distinct() %>%
  pivot_wider(names_from = condition_class, values_from = c("floor", "ceiling"))

# Standardize using thresholds determined above and truncate scores >10 to 10 and <0 to 0
metrics.df.standardized.long.percentiles <- metrics.df.standardized.long %>%
  left_join(metrics.thresholds, by = c("metric", "disturbance")) %>%
  mutate(SCORE = case_when(
    disturbance == "decrease" ~ ((value - floor_3)/(ceiling_1 - floor_3)),
    disturbance == "increase" ~ ((ceiling_3 - value)/(ceiling_3 - floor_1)),
  )) %>%
  mutate(SCORE = SCORE * 10,
         SCORE = if_else(SCORE > 10, 10, SCORE),
         SCORE = if_else(SCORE < 0, 0, SCORE))

#plot rescaled individual metrics
metrics.df.standardized.long.percentiles %>% 
  left_join(condition) %>% 
  filter(metric %in% metrics.final) %>%
  arrange(metric) %>% 
  arrange(condition_class) %>% 
  mutate(metric = factor(metric, levels = unique(metric)),
         condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
  ggplot(aes(condition_class, SCORE)) +
  geom_boxplot() +
  facet_wrap(~metric, ncol = 4, scales = "free") +
  ggtitle("Final metrics (rescaled, all sites)")
# ggsave(file.path(root.dir, "data/IBI/plots_for_pub/rescaling", "metrics_rescaled_midpoint_thresholds.png"), dpi = "print")


# Calculate final IBI scores for all data
metrics.scores <- metrics.df.standardized.long.percentiles %>% 
  select(site_id, metric, SCORE) %>% 
  pivot_wider(names_from = metric, values_from = SCORE) %>% 
  group_by(site_id) %>%
  mutate(SITE_SCORE = sum(c(rich_ttaxa_coe, rich_ttaxa_insecta, pct_gatherer, rich_genus, shannon_ttaxa_shredder))) %>%
  mutate(SITE_SCORE = SITE_SCORE/5) %>%
  ungroup() %>%
  select(site_id, SITE_SCORE, rich_ttaxa_coe, rich_ttaxa_insecta, pct_gatherer, rich_genus, shannon_ttaxa_shredder) %>% 
  left_join(condition)

metrics.scores.cc1 <- metrics.scores %>% 
  filter(site_id %in% train.df.vec,
         condition_class == 1) 
metrics.scores.cc3 <- metrics.scores %>% 
  filter(site_id %in% train.df.vec,
         condition_class ==3)

imp_thresh <- ((quantile(metrics.scores.cc1$SITE_SCORE, probs = 0.25) - 
                  quantile(metrics.scores.cc3$SITE_SCORE, probs = 0.75)) / 2 ) + 
  quantile(metrics.scores.cc3$SITE_SCORE, probs = 0.75)

```

```{r Standardize - Method 2 (midpoints/ranges), eval=FALSE}
# Using midpoints and ranges to LD floor/ceiling


## For metrics decreasing w disturbance:
##   midpoint = mean of 25th of LD and 75th of MD
##   ceiling =  75th of LD
##   floor = midpoint - (75th of LD - midpoint)
## For metrics increasing w disturbance:
##   midpoint = mean of 75th of LD and 25th of MD
##   ceiling = midpoint + (midpoint - 25th of LD)
##   floor = 25th of LD

metrics.midpoints <- metrics.df.standardized.long %>%
  filter(site_id %in% train.df.vec,
         condition_class != 2) %>%
  group_by(metric, condition_class) %>%
  mutate(q25 = quantile(value, probs = 0.25),
         q75 =  quantile(value, probs = 0.75)) %>%
  ungroup() %>%
  select(metric, disturbance, q25, q75, condition_class) %>%
  distinct() %>%
  pivot_wider(names_from = condition_class, values_from = c("q25", "q75")) %>%
  mutate(midpoint = case_when(
    disturbance == "decrease" ~ (q25_1 + q75_3)/2,
    disturbance == "increase" ~ (q75_1 + q25_3)/2)
  )

metrics.thresholds <- metrics.df.standardized.long %>% 
  filter(site_id %in% train.df.vec,
         condition_class != 2) %>% 
  group_by(metric) %>% 
  ungroup() %>% 
  left_join(., metrics.midpoints) %>% 
  mutate(range = case_when(
    disturbance == "decrease" ~ q75_1 - midpoint,
    disturbance == "increase" ~ midpoint - q25_1)
  ) %>%
  mutate(ceiling = case_when(
    disturbance == "decrease" ~ q75_1,
    disturbance == "increase" ~ midpoint + range)
  ) %>%
  mutate(floor = case_when(
    disturbance == "decrease" ~ midpoint - range,
    disturbance == "increase" ~ q25_1)
  ) %>% 
  select(metric, disturbance, floor, ceiling) %>%
  distinct() 

# Standardize using thresholds determined above and truncate scores >10 to 10 and <0 to 0
metrics.df.standardized.long.percentiles <- metrics.df.standardized.long %>%
  left_join(metrics.thresholds, by = c("metric", "disturbance")) %>%
  mutate(SCORE = case_when(
    disturbance == "decrease" ~ ((value - floor)/(ceiling - floor)),
    disturbance == "increase" ~ ((ceiling - value)/(ceiling - floor)),
  )) %>%
  mutate(SCORE = SCORE * 10,
         SCORE = if_else(SCORE > 10, 10, SCORE),
         SCORE = if_else(SCORE < 0, 0, SCORE))

#plot rescaled individual metrics
metrics.df.standardized.long.percentiles %>% 
  left_join(condition) %>% 
  filter(metric %in% metrics.final) %>%
  arrange(metric) %>% 
  arrange(condition_class) %>% 
  mutate(metric = factor(metric, levels = unique(metric)),
         condition_class = factor(condition_class, levels = unique(condition_class))) %>% 
  ggplot(aes(condition_class, SCORE)) +
  geom_boxplot() +
  facet_wrap(~metric, ncol = 4, scales = "free") +
  ggtitle("Final metrics (rescaled, all sites)")
# ggsave(file.path(root.dir, "data/IBI/plots_for_pub/rescaling", "metrics_rescaled_midpoint_thresholds.png"), dpi = "print")


# Calculate final IBI scores for all data
metrics.scores <- metrics.df.standardized.long.percentiles %>% 
  select(site_id, metric, SCORE) %>% 
  pivot_wider(names_from = metric, values_from = SCORE) %>% 
  group_by(site_id) %>%
  mutate(SITE_SCORE = sum(c(rich_ttaxa_coe, rich_ttaxa_insecta, pct_gatherer, rich_genus, shannon_ttaxa_shredder))) %>%
  mutate(SITE_SCORE = SITE_SCORE/5) %>%
  ungroup() %>%
  select(site_id, SITE_SCORE, rich_ttaxa_coe, rich_ttaxa_insecta, pct_gatherer, rich_genus, shannon_ttaxa_shredder) %>% 
  left_join(condition)

metrics.scores.cc1 <- metrics.scores %>% 
  filter(site_id %in% train.df.vec,
         condition_class == 1) 
metrics.scores.cc3 <- metrics.scores %>% 
  filter(site_id %in% train.df.vec,
         condition_class ==3)

imp_thresh <- ((quantile(metrics.scores.cc1$SITE_SCORE, probs = 0.25) - 
                  quantile(metrics.scores.cc3$SITE_SCORE, probs = 0.75)) / 2 ) + 
  quantile(metrics.scores.cc3$SITE_SCORE, probs = 0.75)

```




```{r Standardize - Method 3 (centering), eval=FALSE}

# Determine midpoints between LD and MD classes for each metric (training)
metrics.midpoints <- metrics.df.standardized.long %>%
  filter(site_id %in% train.df.vec,
         condition_class != 2) %>%
  group_by(metric, condition_class) %>%
  mutate(q25 = quantile(value, probs = 0.25),
         q75 =  quantile(value, probs = 0.75)) %>%
  ungroup() %>%
  select(metric, disturbance, q25, q75, condition_class) %>%
  distinct() %>%
  pivot_wider(names_from = condition_class, values_from = c("q25", "q75")) %>%
  mutate(midpoint = case_when(
    disturbance == "decrease" ~ (q25_1 + q75_3)/2,
    disturbance == "increase" ~ (q75_1 + q25_3)/2)
  ) %>%
  select(metric, midpoint)

# Determine standard deviations for each metric (training)
metrics.sd <- metrics.df.standardized.long %>% 
  filter(site_id %in% train.df.vec,
         condition_class != 2) %>% 
  group_by(metric) %>% 
  summarize(stdev = sd(value))

# Join midpoint and SD table for use later
metrics.mid.sd <- metrics.midpoints %>% 
  left_join(., metrics.sd)
rm(metrics.midpoints, metrics.sd)

# Center all data for each metric using midpoints and SDs from training 
metrics.df.standardized.long.centered <- metrics.df.standardized.long %>% 
  # filter(site_id %in% train.df.vec,
  #        condition_class != 2) %>% 
  # group_by(metric) %>% 
  # mutate(stdev = sd(value)) %>% 
  # ungroup() %>% 
  left_join(., metrics.mid.sd) %>% 
  mutate(value_ctr = value - midpoint,
         rescaled = value_ctr/stdev)

# Plot metrics after centering
ggplot(metrics.df.standardized.long.centered, aes(x = as.character(condition_class), y = rescaled)) +
  geom_boxplot() +
  facet_wrap(~metric)

# Take inverse of metrics increasing w disturbance
metrics.centered.scale <- metrics.df.standardized.long.centered %>% 
  mutate(rescaled = ifelse(disturbance %in% "increase", rescaled*-1, rescaled))

# Replot
ggplot(metrics.centered.scale, aes(x = as.character(condition_class), y = rescaled)) +
  geom_boxplot() +
  facet_wrap(~metric)

# Calculate final IBI scores for all data by averaging and rescale from 0-10 using +1 and -1 as the floor and ceiling.
metrics.scores <- metrics.centered.scale %>% 
  select(site_id, metric, rescaled) %>% 
  pivot_wider(names_from = metric, values_from = rescaled) %>% 
  group_by(site_id) %>%
  mutate(SITE_SCORE = sum(c(rich_ttaxa_coe, rich_ttaxa_insecta, pct_gatherer, rich_genus, shannon_ttaxa_shredder))) %>%
  mutate(SITE_SCORE = SITE_SCORE/5,
         SITE_SCORE = if_else(SITE_SCORE > 1, 1, SITE_SCORE),
         SITE_SCORE = if_else(SITE_SCORE < -1, -1, SITE_SCORE),
         SITE_SCORE = (SITE_SCORE * 5) + 5 
  )  %>% 
  ungroup() %>%
  select(site_id, SITE_SCORE, rich_ttaxa_coe, rich_ttaxa_insecta, pct_gatherer, rich_genus, shannon_ttaxa_shredder) %>% 
  left_join(condition)

# Replot
ggplot(metrics.scores, aes(x = as.character(condition_class), y = SITE_SCORE)) +
  geom_boxplot()

```




```{r Final IBI plots, fig.width=3, fig.height=5, eval=FALSE}
# Plot training final scores

metrics.scores.plot <- metrics.scores %>% 
  mutate(class = case_when(
    condition_class == "1" ~ "LD",
    condition_class == "2" ~ "ID",
    condition_class == "3" ~ "MD",
  )) 

  
metrics.scores.plot %>% 
  filter(site_id %in% c(train.df.vec)) %>% 
  mutate(condition_class = factor(class, c("LD", "ID", "MD"))) %>% 
  ggplot(aes(condition_class, SITE_SCORE)) +
  coord_cartesian(ylim = c(0, 10)) +
  geom_boxplot() +
  ggtitle("Training") +
  # xlab(NULL) +
  xlab("Condition Class") +
  ylab("LGBAP Score") 
  # geom_hline(yintercept=imp_thresh, color = "red") 
  # geom_hline(yintercept=4.37, color = "blue") +
  # geom_hline(yintercept=4.8, color = "green") +
  # geom_hline(yintercept=5.79, color = "purple")

  # ggsave(file.path(root.dir, "data/ibi/plots_for_pub/rescaling", "ibi_mid-range_scaling_train.png"), dpi = "print")

# Plot validation final scores
metrics.scores.plot %>% 
  filter(site_id %in% c(test.df.vec)) %>% 
  mutate(condition_class = factor(class, c("LD", "ID", "MD"))) %>% 
  ggplot(aes(condition_class, SITE_SCORE)) +
  coord_cartesian(ylim = c(0, 10)) +
  geom_boxplot() +
  ggtitle("Validation") +
  xlab("Condition Class") +
  ylab("LGBAP Score") 
  # xlab(NULL) +
  # ylab(NULL) +
  # theme(axis.text.y = element_blank(),
        # axis.ticks.y = element_blank()) +
  # ggsave(file.path(root.dir, "data/ibi/plots_for_pub/rescaling", "ibi_mid-range_scaling_val.png"), dpi = "print")

# metrics.scores.val <- metrics.scores.plot %>% 
  # filter(site_id %in% test.df.vec) 

# Plot validation + class 2 (all data plotted minus training) final scores
# metrics.scores.plot %>% 
#   filter(!(site_id %in% train.df.vec)) %>%
#   mutate(condition_class = factor(condition_class, c("1", "2", "3"))) %>% 
#   ggplot(aes(condition_class, SITE_SCORE)) +
#   coord_cartesian(ylim = c(0, 10)) +
#   geom_boxplot() +
#   ggtitle("Final scores (val + class 2)") +
#   xlab("Condition Class") +
#   ylab("LG-BAP Score")

# plot all final scores
metrics.scores.plot %>%
  mutate(condition_class = factor(class, c("LD", "ID", "MD"))) %>% 
  ggplot(aes(condition_class, SITE_SCORE)) +
  coord_cartesian(ylim = c(0, 10)) +
  geom_boxplot() +
  ggtitle("All Sites") +
  # theme(axis.text.y = element_blank(),
  #       axis.ticks.y = element_blank()) +
  # ylab(NULL) +
  # xlab(NULL) +
  xlab("Condition Class") +
  ylab("LGBAP Score") 
  # ggsave(file.path(root.dir, "data/ibi/plots_for_pub/rescaling", "ibi_mid-range_scaling_allsites.png"), dpi = "print")


# Plot all scores, single box and whisker to visualize distribution against scale
metrics.scores.plot %>%
  # mutate(condition_class = factor(condition_class, c("1", "2", "3"))) %>%
  ggplot(aes(condition_class, SITE_SCORE)) +
  coord_cartesian(ylim = c(0, 10)) +
  geom_boxplot() +
  ggtitle("All Sites") +
  # theme(axis.text.y = element_blank(),
  #       axis.ticks.y = element_blank()) +
  # ylab(NULL) +
  # xlab(NULL) +
  xlab("Condition Class") +
  ylab("LGBAP Score") 

```


```{r Model testing}

# Test training

metrics.scores.train <- metrics.scores %>% 
  filter(site_id %in% c(train.df.vec)) %>% 
  mutate(prediction = case_when(
    SITE_SCORE > 5 ~ "1",
    SITE_SCORE < 5 ~ "3",
    # SITE_SCORE > imp_thresh ~ "1",
    # SITE_SCORE < imp_thresh ~ "3",
  )) %>% 
  rename(truth = condition_class) %>% 
  select(truth, prediction) %>% 
  mutate(prediction = factor(prediction, c("1","3"))) %>% 
  mutate(truth = factor(truth, c("1","3")))

metrics.scores.train %>%
  conf_mat(truth, prediction) %>%
  summary() %>%
  filter(.metric %in%
    c("accuracy", "precision", "recall", "f_meas")) %>%
  as_tibble()


# Test validation

metrics.scores.validation <- metrics.scores %>% 
  filter(site_id %in% c(test.df.vec)) %>% 
  mutate(prediction = case_when(
    SITE_SCORE > 5 ~ "1",
    SITE_SCORE < 5 ~ "3",
    # SITE_SCORE > imp_thresh ~ "1",
    # SITE_SCORE < imp_thresh ~ "3",
  )) %>% 
  rename(truth = condition_class) %>% 
  select(truth, prediction) %>% 
  mutate(prediction = factor(prediction, c("1","3"))) %>% 
  mutate(truth = factor(truth, c("1","3")))

metrics.scores.validation %>%
  conf_mat(truth, prediction) %>%
  summary() %>%
  filter(.metric %in%
    c("accuracy", "precision", "recall", "f_meas")) %>%
  as_tibble()

```



```{r Chem vs IBI plot}
# Chemistry (independent dataset) correlations w metrics (all sites (44), final metrics)
chemsites.ibi <- metrics.scores %>%
  select(-condition_class) %>%
  filter(site_id %in% abiotic.chem$site_id) %>% 
  rename(LGBAP = SITE_SCORE)

metrics.cor.chem<-left_join(chemsites.ibi, abiotic.chem, by=c("site_id"))
metric.param.corr.chem<-metrics.cor.chem %>% 
  select(-site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman")
metric.param.corr.chem<-metric.param.corr.chem %>% 
  select(term, LGBAP, all_of(metrics.final)) %>%
  slice(8:33) %>% 
  remove_rownames %>% 
  column_to_rownames(var="term")  
ggcorrplot::ggcorrplot(metric.param.corr.chem)

# Replot using un-standardized scores for indiv metrics

chemsites.ibi.metrics <- metrics.scores %>%
  rename(LGBAP = SITE_SCORE) %>% 
  select(site_id, LGBAP) %>%
  left_join(., chemsites.metrics.final) %>% 
  filter(site_id %in% abiotic.chem$site_id) 

metrics.cor.chem<-left_join(chemsites.ibi.metrics, abiotic.chem, by=c("site_id"))
metric.param.corr.chem<-metrics.cor.chem %>% 
  select(-site_id) %>% 
  correlate(use = "pairwise.complete.obs", method = "spearman")
metric.param.corr.chem<-metric.param.corr.chem %>% 
  select(term, LGBAP, all_of(metrics.final)) %>%
  slice(8:33) %>% 
  remove_rownames %>% 
  column_to_rownames(var="term")  
ggcorrplot::ggcorrplot(metric.param.corr.chem)
```

```{r Look at effect of subsampling on richness}
# counts.subsamp <- read_csv(file.path(root.dir, "data/compile_2015-2019/bugs/counts", "indiv_counts_subsamp_2021-12-01.csv")) %>% 
#   select(site_id, tot)
counts <- read_csv(file.path(root.dir, "data/compile_2015-2019/bugs/counts", "indiv_counts_orig_2021-12-01.csv")) %>%
  select(site_id, tot)

rich.count <- metrics.df %>% 
  select(site_id, rich_ttaxa, condition_class) %>% 
  left_join(., counts)

library(ggplot2)
ggplot(rich.count, aes(x = tot, y = rich_ttaxa)) +
    geom_point()

# ggsave(file.path(root.dir, "data/compile_2015-2019/bugs/counts/count_vs_richness", "count_vs_sp_rich_not_subsampled_2021-12-01.png"), dpi = "print")
# write_csv(rich.count, file.path(root.dir, "data/compile_2015-2019/bugs/counts/count_vs_richness", "count_vs_sp_rich_not_subsampled_2021-12-01.csv"))
```


```{r PC1 correlations, eval = FALSE}









# Matt's code (adapt from this):

all_abiotic_classified <- read_csv(file.path(here::here(),
                                             "data",
                                             "all.abiotic.classified.chem.watershed.csv"))
all_abiotic_classified<-all_abiotic_classified %>% 
  rename(uniqueid = uniqueID)

metric.scores.abiotic<-left_join(metrics.scores, all_abiotic_classified, by=c("uniqueid"))


metric.scores.train<-metric.scores.abiotic %>% 
  filter(uniqueid %in% c(train.df.vec))

metric.scores.validation<-metric.scores.abiotic %>% 
  filter(uniqueid %in% c(test.df.vec))
  
# Training Sites
cor.test(metric.scores.train$SITE_SCORE, metric.scores.train$PC1, method = "pearson")
#Test Sites
cor.test(metric.scores.validation$SITE_SCORE, metric.scores.validation$PC1, method = "pearson")
#All Sites
cor.test(metric.scores.abiotic$SITE_SCORE, metric.scores.abiotic$PC1, method = "pearson")
# Only trainig and test sites
metric.scores.abiotic.subset<-metric.scores.abiotic %>% 
  filter(uniqueid %in% c(train.test.vec))
cor.test(metric.scores.abiotic.subset$SITE_SCORE, metric.scores.abiotic.subset$PC1, method = "pearson")

summary(lm(metric.scores.abiotic$SITE_SCORE~metric.scores.abiotic$PC1))

metric.scores.abiotic %>% 
  #filter(uniqueid %in% c(train.test.vec)) %>% 
  ggplot(aes(COND, SITE_SCORE)) + 
  geom_point()+
  geom_smooth(method=lm)

metric.scores.abiotic %>%
  #filter(uniqueid %in% c(train.test.vec)) %>%
  mutate(class = case_when(
    condition_class == "1" ~ "least disturbed",
    condition_class == "2" ~ "other",
    condition_class == "3" ~ "most disturbed",
  )) %>% 
  ggplot(aes(PC1, SITE_SCORE, shape = class))+
  scale_shape_manual(values=c(3, 4, 8))+
  coord_cartesian(ylim=c(0, 10))+
  geom_point()+
  geom_smooth(method=lm)
```


# Exploring chem vs classes

```{r chem boxplots, fig.width=10, fig.height=12}

abiotic.chem.class <- abiotic.chem %>% 
  left_join(condition) %>% 
  select(site_id, condition_class, everything())

abiotic.chem.long <- abiotic.chem %>% 
  # filter(site_id %in% train.df$site_id) %>% 
  left_join(condition) %>% 
  pivot_longer(cols = c(-condition_class, -site_id),
               names_to = "chem",
               values_to = "value")  %>% 
  #Filter out 17-SWML-1.4 which has extremely high values for better visualization
  filter(!(site_id %in% "17-SWML-1.4"))

abiotic.chem.long %>% 
  mutate(chem = factor(chem, levels = unique(chem)),
         condition_class = factor(condition_class, levels = c("1", "2", "3"))) %>% 
  arrange(condition_class) %>%
  ggplot(aes(condition_class, value)) +
  geom_boxplot() +
  facet_wrap(~chem, ncol = 4, scales = "free")

```

```{r IBI scores vs stressor gradient variables}



#########
#########
# need to replace below with updated data (new PC1, complete habitat scores)
#########
#########



fielddata <- read_csv(file.path(root.dir, "data/compile_2015-2019/field_data/2015-2019_LG_field_landcover_condclasses_20201216.csv")) %>% 
  left_join(metrics.scores, by = "site_id") %>% 
  select(site_id, condition_class.x, habitat_total_score, landcover_nat_pct, spcond, SITE_SCORE, PC1)
fielddata %>% 
  ggplot(aes(x=SITE_SCORE, y=spcond)) + 
  geom_point() +
  geom_smooth(method=lm)
 fielddata %>% 
  ggplot(aes(x=SITE_SCORE, y=landcover_nat_pct)) + 
  geom_point() +
  geom_smooth(method=lm)
 fielddata %>% 
  ggplot(aes(x=SITE_SCORE, y=habitat_total_score)) + 
  geom_point() +
  geom_smooth(method=lm)
fielddata %>% 
  ggplot(aes(x=SITE_SCORE, y=PC1)) + 
  geom_point() +
  geom_smooth(method=lm)

```






##### END TRADITIONAL IBI SECTION #####




#Training and Logistical Regression model

```{r Data prep and model creation}

# Packages at https://www.tidymodels.org/

# Create recipe object
rec_obj <- train_sensitive.df %>% 
  select(condition_class, all_of(metrics.final)) %>% 
  recipe(condition_class ~ ., data = .) %>% 
  # update_role(uniqueid, new_role = "sample_id") %>%
  step_normalize(all_predictors()) %>% 
 # step_nzv(all_predictors()) %>%
 # step_corr(all_predictors(),
  #          threshold = 0.5) %>%
 # step_pca(all_predictors()) %>%
  themis::step_smote(condition_class)
  # step_smote creates a specification of a recipe step that generate new examples of the minority class using nearest neighbors of these cases.
  # Matt says step_smote is redundant if already balanced btw test and ref sites... but removing does not result in an identical DF!


# Extract finalized training set (juice function). Specifiy params for log regr. and engine.

train.juice <- rec_obj %>% 
  prep(training = train_sensitive.df) %>% 
  juice()

logit_mod <- logistic_reg() %>%
  set_engine("stan")

met.flow <- workflow() %>% 
  add_recipe(rec_obj) %>% 
  add_model(logit_mod)

# Provisional set # 1 - Outputs weighting coefficients of metrics used... margalef_ttaxa heavily weighted!!!
(fit_train <- fit(met.flow, data = train_sensitive.df))

```


```{r Cross validation and measuring performace}

# Cross validation tutorial: https://www.youtube.com/watch?v=fSytzGwwBVw 

library(tune)
library(yardstick)

# Training

control <- control_resamples(save_pred = FALSE)
metrics <- metric_set(roc_auc, bal_accuracy, pr_auc)

spline_res <- fit_resamples(logit_mod, rec_obj, train_10cv.df,
                            metrics = metrics,
                            control = control)

show_best(spline_res, metric = "roc_auc")
show_best(spline_res, metric = "bal_accuracy")
show_best(spline_res, metric = "pr_auc")

# Output scores (mean) of 1 would be 100% accurate classification. Zach says anything >75 acceptible (reference?).


# Validation (using test dataset) - dont need bc doing independent validation in confusion matrix below.

control <- control_resamples(save_pred = FALSE)
metrics <- metric_set(roc_auc, bal_accuracy, pr_auc)

spline_res <- fit_resamples(logit_mod, rec_obj, test_10cv.df,
                            metrics = metrics,
                            control = control)

show_best(spline_res, metric = "roc_auc")
show_best(spline_res, metric = "bal_accuracy")
show_best(spline_res, metric = "pr_auc")

```

```{r Create logistical regression model}

test.df <- testing(train_test_split) %>% 
  filter(condition_class %in% c("1", "3")) %>% 
   select(condition_class, all_of(metrics.final))

#Training
pred_test <- predict(fit_train, new_data = train_sensitive.df, type = "prob") %>% 
  bind_cols(select(train_sensitive.df, condition_class))

# Validation (don't need this bc doing independent validation in confusion matrix below.)
pred_test_validation <- predict(fit_train, new_data = test.df, type = "prob") %>% 
  bind_cols(select(test.df, condition_class))
pred_test_all <- predict(fit_train, new_data = metrics.df, type = "prob") %>% 
  bind_cols(select(metrics.df, condition_class))


```


```{r Logistical regression model plots}

# Training

pred_test %>% 
  # filter(condition_class %in% c("1", "4")) %>% 
  mutate(condition_class = as.character(condition_class)) %>% 
  mutate(condition = case_when(
    condition_class %in% "3" ~ 1,
    condition_class %in% "1" ~ 0,
    TRUE ~ 9999
  )) %>% 
ggplot(aes(.pred_1, condition)) +
  geom_point() +
  stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) 

# Validation (not needed; just plotting for visual comparison)

pred_test_validation %>% 
  # filter(condition_class %in% c("1", "4")) %>% 
  mutate(condition_class = as.character(condition_class)) %>% 
  mutate(condition = case_when(
    condition_class %in% "3" ~ 1,
    condition_class %in% "1" ~ 0,
    TRUE ~ 9999
  )) %>% 
ggplot(aes(.pred_1, condition)) +
  geom_point() +
  stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) 

#All Data (not needed; just plotting for visual comparison)

pred_test_all %>% 
  filter(condition_class %in% c("1", "3")) %>% 
  mutate(condition_class = as.character(condition_class)) %>% 
  mutate(condition = case_when(
    condition_class %in% "3" ~ 1,
    condition_class %in% "1" ~ 0,
    TRUE ~ 9999
  )) %>% 
ggplot(aes(.pred_1, condition)) +
  geom_point() +
  stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial)) 

```

```{r Visualize model performance (ROC curve)}

# Receiver operator curve
# Add in resampling as shown at https://yardstick.tidymodels.org/ ?
# Look up sensitivity vs specificity

# Training
# Goal is for model to have high sensitivity ("curve" tighter to top left corner). 


simple_glm_roc <- pred_test %>% 
  roc_curve(factor(condition_class), .pred_1)
# computes the area under the ROC curve
pred_test_validation %>% 
  roc_auc(factor(condition_class), .pred_1)
autoplot(simple_glm_roc)


# Validation (not needed?; just plotting for visual comparison)

simple_glm_roc <- pred_test_validation %>% 
  roc_curve(factor(condition_class), .pred_1)
pred_test_validation %>% 
  roc_auc(factor(condition_class), .pred_1)
autoplot(simple_glm_roc)



```

## Probilities from log regr. for each class - Summary of results!

```{r Log regr boxplot}


# ***Training***

train.df <- predict(fit_train, new_data = training(train_test_split), type = "prob") %>% 
  bind_cols(select(training(train_test_split), condition_class))

train.df %>% 
  mutate(condition_class = factor(condition_class, c("1", "2", "3"))) %>% 
ggplot(aes(condition_class, .pred_1)) +
  geom_boxplot()

#Validation

test.df <- predict(fit_train, new_data = testing(train_test_split), type = "prob") %>% 
  bind_cols(select(testing(train_test_split), condition_class, site_id))

test.df %>% 
  mutate(condition_class = factor(condition_class, c("1", "2", "3"))) %>% 
ggplot(aes(condition_class, .pred_1)) +
  geom_boxplot()

#All Data 

all.df <- predict(fit_train, new_data = metrics.df, type = "prob") %>% 
  bind_cols(select(metrics.df, condition_class, site_id))

all.df %>% 
  mutate(condition_class = factor(condition_class, c("1", "2", "3"))) %>% 
ggplot(aes(condition_class, .pred_1)) +
  geom_boxplot()

### LOOK AT OUTLIERS
all.df.outliers.cl3 <- all.df %>% 
  filter(condition_class == 3,
         .pred_1 > 0.5) %>% 
  pull(site_id)

all.df.outliers.cl1 <- all.df %>% 
  filter(condition_class == 1,
         .pred_1 < 0.25) %>% 
  pull(site_id)

outliers.all <- c(all.df.outliers.cl3, all.df.outliers.cl1) %>% 
  cat(sep = "\n")



```

```{r, confusion matrix accuracy assessment for validation dataset}

test.df <- predict(fit_train, new_data = testing(train_test_split), type = "prob") %>% 
  bind_cols(select(testing(train_test_split), condition_class, site_id))

# Assign prediction probabilities 
test.df.confuse<-test.df %>% 
  mutate(condition_class = factor(condition_class, c("1","3"))) %>%
  filter(condition_class %in% c("1","3")) %>% 
  mutate(prediction = case_when(
    .pred_1>0.5 ~ "1",
    .pred_1<0.5 ~ "3",
  )) %>% 
  rename(truth = condition_class) %>% 
  mutate(prediction = factor(prediction, c("1","3")))
  

test.df.confuse %>%
  conf_mat(truth, prediction) %>%
  summary() %>%
  filter(.metric %in%
    c("accuracy", "precision", "recall", "f_meas")) %>%
  as_tibble()
  
```
